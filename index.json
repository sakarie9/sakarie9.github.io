[{"content":"","date":"2025-08-21","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"2025-08-21","externalUrl":null,"permalink":"/tags/games/","section":"Tags","summary":"","title":"Games","type":"tags"},{"content":" Introduction # PFS is a proprietary archive format used by the Artemis visual novel engine. This format serves as a container for game assets, allowing developers to package multiple files into a single archive for distribution and efficient asset management.\nThis document provides a complete technical specification of the PFS file format, reverse-engineered through analysis of actual game files. The information presented here enables developers to create tools for extracting, analyzing, and manipulating PFS archives.\nRelated Tools # I have developed several tools for working with PFS files:\npf8 - A Rust library providing encoding and decoding functionality for PFS files pfs-rs - A command-line tool for packing and unpacking PFS archives sakarie9/pfs-rs Artemis .pfs file unpacker and packer written in rust Rust 11 1 PFS File Format Structure # The PFS format uses a structured approach to store file metadata and data. The format consists of a header section containing file indices and metadata, followed by the actual file data. This design allows for efficient random access to individual files within the archive.\nImportant: All multi-byte values in PFS files are stored in little-endian byte order. Header Structure # Offset Size Name Description 0x0 0x3 Magic Number File signature: pf8 0x3 0x4 Index Size Size from File Count start to File Size Count Offset end: [0x7, 0x1B+X+Y) 0x7 0x4 File Count Total number of files in the archive 0xB X File Entries Array of file entry structures. See Below 0xB+X 0x4 File Size Count Number of file size entries (File Count + 1) 0xF+X Y=0x8*(FileCount) File Size Offsets Array of 8-byte offsets pointing to file sizes in File Entries. See Below 0xF+X+Y 0x8 File Size Offset End Padding bytes (filled with zeros) 0x17+X+Y 0x4 File Size Count Offset Offset to File Size Count field, calculated from position 0x7 File Entry Structure # For clarity, offsets shown below start from 0x0. Remember to add the file entry base offset of 0xB when working with the complete PFS file.\nOffset Size Name Description 0x0 0x4 File Name Length Length of the filename in bytes 0x4 X=FileNameLength File Name Filename string (length specified by previous field) 0x4+X 0x4 Null Terminator String terminator (filled with zeros) 0x8+X 0x4 Offset Absolute offset to file data within the PFS file.See Below 0xC+X 0x4 File Size Size of the file data in bytes Understanding File Data Offsets # The offset field in each file entry represents the absolute position of the file data within the entire PFS file, not relative to the file entry itself.\nExample: For a file entry with offset=0xBD and size=0x000326C8, the file data spans from byte 0xBD to byte 0xBD + 0x000326C8 in the PFS file. In array notation: \u0026amp;pfs[offset..offset+size].\nFile Size Offset Structure # Each entry in the File Size Offsets array is an 8-byte offset value that points to the corresponding file size within the File Entries section.\nImportant: The offset is calculated relative to position 0xF (the start of the File Size Offsets array).\nExample: If a file size offset contains the value 0x25, the actual file size can be read from \u0026amp;pfs[0x25+0xF..0x25+0xF+0x4].\nEncryption # todo\n","date":"2025-08-21","externalUrl":null,"permalink":"/posts/2025/artemis-pfs/","section":"Posts","summary":"A comprehensive analysis of the PFS file format structure used by the Artemis game engine, including detailed breakdowns of headers, file entries, and offset calculations.","title":"Parsing PFS Files Used by the Artemis Engine","type":"posts"},{"content":"","date":"2025-08-21","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"2025-08-21","externalUrl":null,"permalink":"/","section":"Sakari's Blog","summary":"","title":"Sakari's Blog","type":"page"},{"content":"","date":"2025-08-21","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2025-08-21","externalUrl":null,"permalink":"/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/","section":"Categories","summary":"","title":"技术分享","type":"categories"},{"content":"","date":"2025-08-12","externalUrl":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"有些特定版本的 Minecraft 可能会在 Linux/Pipewire 中存在没有声音或者直接崩溃的问题\nOpenAL 会优先使用 JACK 而非 PipeWire 的 PulseAudio 后端，将其指定为 PulseAudio 可解决此问题\n新建 /etc/openal/alsoft.conf (或 ~/.alsoftrc；或 $XDG_CONFIG_HOME/alsoft.conf)\ndrivers=pulse 或者使用环境变量 ALSOFT_DRIVERS=pulse 也用同样的作用\n参考：ArchWiki\n","date":"2025-08-12","externalUrl":null,"permalink":"/posts/2025/minecraft-pipewire-audio/","section":"Posts","summary":"","title":"Minecraft 在 Pipewire 上没有声音的问题","type":"posts"},{"content":"","date":"2025-08-12","externalUrl":null,"permalink":"/categories/%E6%8A%80%E6%9C%AF%E9%9A%8F%E7%AC%94/","section":"Categories","summary":"","title":"技术随笔","type":"categories"},{"content":"","date":"2025-07-27","externalUrl":null,"permalink":"/tags/audio/","section":"Tags","summary":"","title":"Audio","type":"tags"},{"content":" 前言 # 虽然在 Linux 上在输出设备上应用均衡器等音效的一般实践是使用 EasyEffects，但对于简单的均衡器来说，EE 太重了，而且在使用时偶尔会出现音频卡顿等奇怪的现象。正好 Pipewire 本身就有配置音效的功能，所以本文尝试使用 Pipewire 实现均衡器。\n准备 # 首先确保 Pipewire 已经安装并正常运作。\n然后明确要配置的 EQ 的参数，例如参数均衡器：\nFilter 1 : ON LSC Fc 105.0 Hz Gain 0.6 dB Q 0.70 Filter 2 : ON PK Fc 37.7 Hz Gain -1.0 dB Q 2.06 Filter 3 : ON PK Fc 158.4 Hz Gain -7.1 dB Q 0.69 Filter 4 : ON PK Fc 620.1 Hz Gain 2.6 dB Q 1.78 Filter 5 : ON PK Fc 1097.3 Hz Gain -2.9 dB Q 2.30 Filter 6 : ON PK Fc 2235.0 Hz Gain 3.3 dB Q 2.46 Filter 7 : ON PK Fc 3671.3 Hz Gain 6.9 dB Q 0.98 Filter 8 : ON PK Fc 5803.3 Hz Gain -7.2 dB Q 3.86 Filter 9 : ON PK Fc 8349.1 Hz Gain -2.2 dB Q 3.49 Filter 10: ON HSC Fc 10000.0 Hz Gain 8.7 dB Q 0.70 或者简单的图形均衡器：\n\u0026#34;31.5Hz\u0026#34; : 0.0 \u0026#34;63Hz\u0026#34; : 0.0 \u0026#34;125Hz\u0026#34; : 0.0 \u0026#34;250Hz\u0026#34; : 0.0 \u0026#34;500Hz\u0026#34; : 0.0 \u0026#34;1000Hz\u0026#34; : 0.0 \u0026#34;2000Hz\u0026#34; : 0.0 \u0026#34;4000Hz\u0026#34; : 0.0 \u0026#34;8000Hz\u0026#34; : 0.0 \u0026#34;16000Hz\u0026#34; : 0.0 如果没有找到针对所用的音频设备的参数表，可以尝试自己写一个。简单的方法是使用 EasyEffects，其可以方便地预览不同参数的效果。\n拥有合适的 EQ 配置后，开始编写配置文件。\n配置 # 以参数均衡器为例。\n创建 ~/.config/pipewire/pipewire.conf.d/eq.conf，文件名可以随意，写入以下内容：\ncontext.modules = [ { name = libpipewire-module-filter-chain args = { node.description = \u0026#34;EQ Sink\u0026#34; media.name = \u0026#34;EQ Sink\u0026#34; filter.graph = { nodes = [ { type = builtin name = eq_band_1 label = bq_lowshelf control = { \u0026#34;Freq\u0026#34; = 130 \u0026#34;Q\u0026#34; = 0.5 \u0026#34;Gain\u0026#34; = -2.0 } } { type = builtin name = eq_band_2 label = bq_highshelf control = { \u0026#34;Freq\u0026#34; = 3350 \u0026#34;Q\u0026#34; = 1.25 \u0026#34;Gain\u0026#34; = 3.5 } } ] links = [ { output = \u0026#34;eq_band_1:Out\u0026#34; input = \u0026#34;eq_band_2:In\u0026#34; } ] } audio.channels = 2 audio.position = [ FL FR ] capture.props = { node.name = \u0026#34;effect_input.eq\u0026#34; media.class = \u0026#34;Audio/Sink\u0026#34; } playback.props = { node.name = \u0026#34;effect_output.eq\u0026#34; node.passive = true } } } ] 上面的配置最终看起来就是这样的曲线：\n下面是几个需要关注的参数：\n其中 nodes 节点下面就是每个频率对应的参数，这里只设置两组：\n\u0026#34;Freq\u0026#34; = 130 \u0026#34;Q\u0026#34; = 0.5 \u0026#34;Gain\u0026#34; = -2.0 bq_lowshelf \u0026#34;Freq\u0026#34; = 3350 \u0026#34;Q\u0026#34; = 1.25 \u0026#34;Gain\u0026#34; = 3.5 bq_highshelf Freq: 中心频率。 Q: 带宽或 Q 值 (Bandwidth/Q-Factor)，影响范围的宽度。Q 值越高，影响的频率范围越窄（越尖锐）；Q 值越低，影响的范围越宽（越平缓）。 Gain: 增益，提升或衰减多少分贝 (dB)。 滤波器: bq_lowshelf/bq_highshelf 等，除此之外还有很多其他的，可以在 EasyEffects 中测试。 links 将 nodes 串联起来，这里的作用就是将 eq_band_1 的输出，作为 eq_band_2 的输入。如果有更多则以此类推，将 eq_band_2 的输出作为 eq_band_3 的输入。写法为：\nlinks = [ { output = \u0026#34;eq_band_1:Out\u0026#34; input = \u0026#34;eq_band_2:In\u0026#34; } { output = \u0026#34;eq_band_2:Out\u0026#34; input = \u0026#34;eq_band_3:In\u0026#34; } ] media.name 可以随意修改，最终作为输出设备出现在输出选择中的就会是这个名字。\n配置完成之后使用 systemctl --user restart pipewire pipewire-pulse wireplumber 重启 pipewire\n效果 # 如果配置正确，你会在 pavucontrol 等能够看到输出设备的软件中发现一个新的输出设备 EQ Sink，将其设置为默认输出设备就能应用到上面配置的 EQ 了。\n在 Helvum 中查看，能发现此时 EQ Sink 连接到了默认硬件输出设备上：\n上面的 EQ Sink 为输入，所有应用的音频输出汇集到其中，再由下面的 EQ Sink 输出到硬件。\n多输出设备 # 上述方案存在一些问题，例如当拥有多个硬件音频输出设备时， EQ Sink 有可能连接到错误的设备上。\n例如一台同时拥有音响和耳机输出的计算机，上述方案的 EQ Sink 会选择他认为的“默认”硬件输出设备进行连接，就可能出现预期输出是耳机，但实际在音响播放音频的情况。\n为了避免这个问题，我们将 EQ 与硬件输出进行绑定。\n在配置文件中修改 playback.props：\nplayback.props = { node.name = \u0026#34;effect_output.eq\u0026#34; node.passive = true # 在这里添加目标设备! # 将下面的值替换为你的实际设备名 target.object = \u0026#34;alsa_output.pci-0000_30_00.1.hdmi-stereo\u0026#34; target.object 的值可以使用 pw-link -l 进行查看。\n如此配置之后，输出设备中的 EQ Sink 将会永远与 target.object 进行绑定。\n例如将其绑定在了音响上，那么如果将 EQ Sink 设为默认输出，声音会从音响出来。当需要切换到耳机时，将输出设备更改为耳机即可。\n结语 # 虽然 Pipewire 配置起来相比 EasyEffects 更为繁琐，但其原生实现的特性可以保证音频链的相对整洁，可能也有一些性能上的提高，也能降低由于 EasyEffects 依赖图形界面而增加的内存占用。\n参考 # 使用 PipeWire 实现自动应用均衡器 - 依云\u0026rsquo;s Blog Linux好声音（干净的均衡器） - 知乎 ","date":"2025-07-27","externalUrl":null,"permalink":"/posts/2025/pipewire-eq/","section":"Posts","summary":"","title":"使用 Pipewire 实现音频均衡器","type":"posts"},{"content":" 问题 # ASUS RT-AC86U 系统日志中频繁出现\nJun 23 21:33:47 kernel: nf_conntrack: expectation table full Jun 23 21:33:47 kernel: nf_conntrack: expectation table full Jun 23 21:33:47 kernel: nf_conntrack: expectation table full Jun 23 21:33:47 kernel: nf_conntrack: expectation table full 解决 # 进入路由器的 ssh\n使用如下命令查看原始值，此时为 150\ncat /proc/sys/net/netfilter/nf_conntrack_expect_max 使用如下命令将默认值提高\nnvram set ct_expect_max=1024 nvram commit 重启生效\nreboot ","date":"2025-06-23","externalUrl":null,"permalink":"/posts/2025/asus-router-nf/","section":"Posts","summary":"如何解决 kernel: nf_conntrack: expectation table full","title":"ASUS Router nf_conntrack expectation table full","type":"posts"},{"content":"","date":"2025-06-23","externalUrl":null,"permalink":"/tags/network/","section":"Tags","summary":"","title":"Network","type":"tags"},{"content":" 参考 Patching packages - ArchWiki\n前言 # 例如，要对 waybar-git 应用一个 尚未合并的 pr (假设为 #114514)\n如果不使用 Arch build system，需要手动构建包，不利于软件包的管理\n因此通过修改 PKGBUILD 的方式，对软件包进行 patch\n步骤 # 获取 patch # 对于 GitHub 或者 GitLab，可以在 URL 后附加 .patch 来为特定提交或合并/拉取请求生成补丁\n例如 https://github.com/Alexays/Waybar/pull/114514.patch\nPKGBUILD # 从 Arch Linux GitLab 或者 AUR 获得对应包的 PKGBUILD，如果包括其他文件需要一并下载\n将获取到的 patch 链接或者 patch 文件添加到将 PKGBUILD 中的 source 内，同时添加对应的 checksum\n然后应用补丁，在 prepare() 中添加\nprepare() { cd $pkgname-$pkgver # edit patch -Np1 -i ../114514.patch } 构建 # 完成上述步骤和就可以使用 makepkg 或者 extra-x86_64-build 构建包了\n注意如果软件源中的包更新后版本比 patch 过的包更新，则 patch 过的包会被覆盖，需要更新 PKGBUILD 后重新构建\n","date":"2025-05-07","externalUrl":null,"permalink":"/posts/2025/arch-abs-patch/","section":"Posts","summary":"","title":"Arch 应用软件包补丁","type":"posts"},{"content":" 前言 # 当 Linux 中存在多张显卡时，理所当然的会存在程序显卡选择上的问题。\n例如游戏选择了核显而非独显运行，浏览器选择了解码单元较弱且较为耗电的独显运行。\n这些是用户所不希望的行为，所幸，mesa 给我们提供了一些可以手动指定显卡设备的环境变量。\n默认情况 # 我们可以使用 MESA_VK_DEVICE_SELECT=list vulkaninfo 查看当前可用的显卡信息。\nselectable devices: GPU 0: 1002:67df \u0026#34;AMD Radeon RX 580 Series (RADV POLARIS10)\u0026#34; discrete GPU 0000:10:00.0 GPU 1: 1002:1638 \u0026#34;AMD Radeon Graphics (RADV RENOIR)\u0026#34; integrated GPU 0000:30:00.0 例如这里拥有两张显卡，GPU 0 为独立显卡 (dGPU)，GPU 1 为核显 (iGPU)。\n使用 glxinfo 和 vkcube 来进行 opengl 和 vulkan 应用的简单测试。\n❯ glxinfo | rg Device Device: AMD Radeon Graphics (radeonsi, renoir, ACO, DRM 3.61, 6.14.2-2-cachyos) (0x1638) ❯ vkcube Selected WSI platform: xcb Selected GPU 1: AMD Radeon RX 580 Series (RADV POLARIS10), type: DiscreteGpu 其中 glxinfo 选择了核显，而 vkcube 选择了独显。\n根据 mesa #24750 所述，vkcube 似乎总是会优先适用独显\n环境变量 # 在 mesa 的文档中，我们注意到其中 DRI_PRIME 和 MESA_VK_DEVICE_SELECT 这两个变量是和设备选择相关的。\nDRI_PRIME\n默认 GPU 是 Wayland/Xorg 使用的或连接到显示器的 GPU。此变量允许选择不同的 GPU。它适用于 OpenGL 和 Vulkan（在这种情况下，“选择”意味着该 GPU 将排在报告的物理设备列表的首位）。支持的语法有：\nDRI_PRIME=N : 选择第 N 个非默认 GPU（N \u0026gt; 0）。 DRI_PRIME=pci-0000_02_00_0 : 选择连接到此 PCIe 总线的 GPU DRI_PRIME=vendor_id:device_id : 选择匹配这些 ID 的第一个 GPU。 对于 Vulkan，可以附加 ! ，这样只有选定的 GPU 会暴露给应用程序（例如：DRI_PRIME=1!）。\nMESA_VK_DEVICE_SELECT\n当设置为“list”时，打印设备列表。当设置为“vid:did”时，从 PCI 设备中选择编号。该 PCI 设备将被设为默认设备。默认设备会在 vkEnumeratePhysicalDevices API 中作为第一个设备返回。使用“vid:did!”的效果与使用 MESA_VK_DEVICE_SELECT_FORCE_DEFAULT_DEVICE 变量相同。即被识别为默认的设备将是 vkEnumeratePhysicalDevices API 中唯一返回的设备。\n配置 # 由于 DRI_PRIME 已经适用于 OpenGL 和 Vulkan，一般情况下只需要配置它就足够了。\n经测试，在两者同时设置时，MESA_VK_DEVICE_SELECT 似乎会优先于 DRI_PRIME 对 vkcube 生效\n虽然 DRI_PRIME 支持 DRI_PRIME=N 的写法，这里不建议这样使用，因为 DRI_PRIME=N! 并不能强制使应用使用序号为 N 的显卡。\n❯ DRI_PRIME=0! vkcube Selected WSI platform: xcb Selected GPU 1: AMD Radeon RX 580 Series (RADV POLARIS10), type: DiscreteGpu ❯ DRI_PRIME=1! vkcube Selected WSI platform: xcb Selected GPU 0: AMD Radeon RX 580 Series (RADV POLARIS10), type: DiscreteGpu 而使用 DRI_PRIME=vendor_id:device_id! 时正常运作。\n❯ DRI_PRIME=1002:1638! vkcube Selected WSI platform: xcb Selected GPU 0: AMD Radeon Graphics (RADV RENOIR), type: IntegratedGpu 因此，在我们想要指定显卡的应用程序运行前加上 DRI_PRIME=vendor_id:device_id! 就能强制使其使用指定的显卡了。\n应用 # 使用 MESA_VK_DEVICE_SELECT=list vulkaninfo 查看显卡 id，替换下面样例中的 vid:did\n一般情况下，使用带感叹号 DRI_PRIME=vid:did! 的并不必要，其会使 vid:did 对应的设备成为应用程序中唯一可见的设备。\n建议仅当指定了设备，但应用仍然默认使用另一张显卡或同时使用多张显卡时才使用 !。\nSteam # 右键游戏 - 属性 - 通用 - 启动选项中填入 DRI_PRIME=vid:did %command% 即可。\n命令行程序 # DRI_PRIME=vid:did example_binary\n或\nenv DRI_PRIME=vid:did example_binary\n通过 drun 或 launcher 启动的软件 # 修改其入口 /usr/share/applications/whatever.desktop，在 Exec 字段最前面插入 env DRI_PRIME=vid:did。\n例如 Exec=env DRI_PRIME=vid:did whatever %F\n建议将对应的 .desktop 文件复制到 ~/.local/share/applications/ 中，避免应用更新后 .desktop 被覆盖\n全局 # 不太推荐，可能会搞坏一些东西\n如果在将显卡 A（例如核显）用作所有的桌面渲染、视频输出（连接显示器）；显卡 B 只在运行游戏、AI 或其他更适合在 B 上运行的任务时手动指定调用，则可以考虑将 DRI_PRIME 设置为全局变量。这样可以将大部分的日常任务负载从显卡 B 上转移到显卡 A，可以维持显卡 B 的长时间休眠以省下一些电以及降低些许温度（理论上）。\n编辑 /etc/environment（对系统生效）或者 ~/.profile （对用户生效），添加 DRI_PRIME=vid:did。\n包装脚本 # 你可以使用一个脚本来更方便地使用环境变量。或者同时使用 mangohud gamemode 等。\n在 ~/.local/bin 中创建一个脚本 exec-dgpu。\n#!/bin/bash DRI_PRIME=vid:did \u0026#34;$@\u0026#34; 在运行软件时只需要 exec-dgpu whatever 即可。\n","date":"2025-04-14","externalUrl":null,"permalink":"/posts/2025/linux-multi-gpu-select/","section":"Posts","summary":"多显卡设备中的显卡指定方式和设置","title":"Linux 多显卡设备中的显卡指定","type":"posts"},{"content":" 前言 # 在 /etc/systemd/resolved.conf 中配置的 DNS，优先级总是低于接口配置的 DNS\n按照 接口DNS -\u0026gt; 接口DHCP DNS -\u0026gt; resolved 的优先级依次生效\n例如使用 resolvectl status\nGlobal Protocols: +LLMNR +mDNS DNSOverTLS=opportunistic DNSSEC=no/unsupported resolv.conf mode: stub Current DNS Server: 223.5.5.5#dns.alidns.com DNS Servers: 223.5.5.5#dns.alidns.com Fallback DNS Servers: 1.0.0.1#cloudflare-dns.com 9.9.9.9#dns.quad9.net 2606:4700:4700::1111#cloudflare-dns.com 2620:fe::9#dns.quad9.net DNS Domain: ~. Link 2 (enp34s0) Current Scopes: DNS LLMNR/IPv4 LLMNR/IPv6 mDNS/IPv4 mDNS/IPv6 Protocols: +DefaultRoute +LLMNR +mDNS DNSOverTLS=opportunistic DNSSEC=no/unsupported Current DNS Server: 2400:3200::1 DNS Servers: 223.5.5.5 192.168.50.1 2400:3200::1 Default Route: yes 可以看到 enp34s0 中已经存在 DNS，这是从 DHCP 中获取的\n但我们想要全局控制 DNS，在 /etc/systemd/resolved.conf 中配置的 DNS 作为全局生效\n配置 # systemd-networkd # 在对应接口的 network 文件，例如 /etc/systemd/network/enp34s0.network 中禁用 DHCP DNS\n[Network] DHCP=yes [DHCPv4] UseDNS=no [DHCPv6] UseDNS=no 如果在使用 IPv6AcceptRA，还需要禁用它的 DNS\n[Network] IPv6AcceptRA = true [IPv6AcceptRA] UseDNS=no NetworkManager # 这里使用 nmtui，在 编辑连接-选择接口 中，分别在 IPv4 配置 和 IPv6 配置中，勾选 忽略自动获取的DNS参数，使用空格在选项上打钩\n配置完成后应该如下，接口的 DNS 会消失\nGlobal Protocols: +LLMNR +mDNS DNSOverTLS=opportunistic DNSSEC=no/unsupported resolv.conf mode: stub Current DNS Server: 223.5.5.5#dns.alidns.com DNS Servers: 223.5.5.5#dns.alidns.com Fallback DNS Servers: 1.0.0.1#cloudflare-dns.com 9.9.9.9#dns.quad9.net 2606:4700:4700::1111#cloudflare-dns.com 2620:fe::9#dns.quad9.net DNS Domain: ~. Link 2 (enp34s0) Current Scopes: LLMNR/IPv4 LLMNR/IPv6 mDNS/IPv4 mDNS/IPv6 Protocols: -DefaultRoute +LLMNR +mDNS DNSOverTLS=opportunistic DNSSEC=no/unsupported Default Route: no ","date":"2025-03-12","externalUrl":null,"permalink":"/posts/2025/systemd-resolved-dns/","section":"Posts","summary":"","title":"让 systemd-resolved 全局生效","type":"posts"},{"content":" \u0026lt;input placeholder=\"数字间逗号分隔\" value=\"1,3,5,7,?\" id=\"numbers\" /\u003e \u0026lt;h1\u003e试着找出问号所代表的数\u0026lt;/h1\u003e \u0026lt;p\u003e 正确答案是\u0026lt;/p\u003e \u0026lt;mark\u003e114514\u0026lt;/mark\u003e \u0026lt;p\u003e因为当\u0026lt;/p\u003e \u0026lt;div id=\"function\"\u003e\u0026lt;/div\u003e \u0026lt;ul id=\"function-values\"\u003e\u0026lt;/ul\u003e \u0026lt;p\u003e真有逻辑！真是有趣！哇！数学！哇！\u0026lt;/p\u003e html, body { height: 100%; background: hsl(216, 69%, 95%); } input { border: 3px solid rgba(0, 0, 0, .09); border-radius: 8px; font-size: 45px; text-align: center; background: transparent; color: hsl(216, 90%, 43%); font-family: 'Monaco', monospace; font-weight: 700; transition: border .2s ease, background .2s ease; outline: none; background: rgba(0, 0, 0, .01); max-width: 95vw; } input:hover { border: 3px solid rgba(0, 0, 0, .23); } input:focus { border: 3px solid hsl(216, 90%, 43%); background: hsla(204, 100%, 88%, .4); } body { margin: 0; padding: 10vh 0 5vh; display: flex; flex-direction: column; align-items: center; } mark { background: hsl(138, 56%, 85%); color: hsl(138, 90%, 43%); font-family: \u0026lsquo;Monaco\u0026rsquo;, monospace; font-weight: 700; margin: 12px; padding: 0 16px; height: 64px; line-height: 64px; font-size: 40px; border-radius: 32px; }\nul \u0026gt; li { list-style: none; }\n.homo-value { color: hsl(15, 99%, 57%); }\n//线性方程组（n元一次方程组）求解库 import * as linear from \"https://cdn.skypack.dev/linear-solve@1.2.1\"; const functionContainer = document.getElementById('function'); const functionValuesContainer = document.getElementById('function-values'); document.getElementById('numbers').addEventListener('input', ({target}) =\u003e { //清除旧函数 functionValuesContainer.innerHTML = ''; functionContainer.innerHTML = ''; const numbers = target.value.split(',').map(number =\u003e { const parsed = parseFloat(number); return isFinite(parsed) ? parsed : 114514; //NaN、Infinity当问号处理 }); const exponents = Array(numbers.length).fill(numbers.length - 1).map((number, exponent) =\u003e number - exponent); const products = linear.solve(Array(numbers.length).fill(0).map( (v, index) =\u003e exponents.map(exponent =\u003e (index + 1) ** exponent) ), [...numbers]) .map((solution, index, solutions) =\u003e { let product = ''; if(solution) { if(index) product += solution \u003e 0 ? '+' : '-'; product += Math.abs(solution).toFixed(3); if(solutions.length - index - 1) { product += 'x'; if(solutions.length - index - 2) product += `^${exponents[index]}`; } } return product; }); katex.render(`f(x) = ${products.join('')}`, functionContainer, { throwOnError: false }); for(let [index, number] of numbers.entries()) { const functionValue = document.createElement('li'); if(number === 114514) functionValue.classList.add('homo-value'); katex.render(`f(${index + 1}) = ${number}`, functionValue, { throwOnError: false }); functionValuesContainer.append(functionValue); } }); document.getElementById('numbers').dispatchEvent(new InputEvent('input')); ","date":"2025-02-27","externalUrl":null,"permalink":"/posts/2025/114514/","section":"Posts","summary":"真有逻辑！真是有趣！哇！数学！哇！","title":"试着找出问号所代表的数","type":"posts"},{"content":" 为什么需要调整文件描述符限制？ # 1. 默认限制的局限性 # Arch Linux 默认的 open files 限制为：\n$ ulimit -n 1024 # 普通用户默认 soft limit $ ulimit -Hn 524288 # hard limit 这个限制对于以下场景明显不足：\n高并发 Web 服务（Nginx/Apache） 数据库系统（MySQL/Redis） 大数据处理（Spark/Hadoop） 游戏服务器（需要加载大量资源文件） 2. 不调整的风险案例 # # 典型错误日志示例 java.io.IOException: Too many open files nginx: [alert] 4096 worker_connections exceed open file resource limit: 1024 Unhandled Exception: EETypeRva:0x00667F40: Too many open files 配置 # 步骤 1：创建配置文件 # 创建文件 /etc/security/limits.d/10-nofile-limits.conf：\n# - nofile - max number of open file descriptors * soft nofile 8192 # 所有用户 soft limit # * hard nofile 524288 # 保留系统默认 hard limit 对 systemd 单元，在 /etc/systemd/system.conf 和 /etc/systemd/user.conf 中添加：\nDefaultLimitNOFILE=8192:524288 步骤 2：立即生效配置 # # 对于已登录用户需要重新登录 ssh localhost # 快速重新建立会话 # 验证当前限制 ulimit -Sn \u0026amp;\u0026amp; ulimit -Hn # 应输出： # 8192 # 524288 步骤 3：系统级监控（可选） # # 查看全局文件描述符使用 watch -n 5 \u0026#34;cat /proc/sys/fs/file-nr\u0026#34; # 输出示例： # 7584 0 3254236 # 分别表示：已分配 | 未使用 | 系统上限 高级技巧与排错 # systemd 服务的特殊处理 # 使用 systemd 管理的服务需要额外配置：\n# 编辑 systemd 全局配置 sudo nano /etc/systemd/system.conf # 修改以下参数： DefaultLimitNOFILE=8192:524288 重启服务生效：\nsudo systemctl daemon-reload sudo systemctl restart your-service 常见问题排查 # Q：修改后限制未生效？\n确认用户已重新登录 检查 sshd_config 是否启用 UsePAM yes 使用 cat /proc/\u0026lt;PID\u0026gt;/limits 验证进程实际限制 Q：应该设置多大的值？\n应用类型 推荐 soft limit Web 服务器 65535-131072 数据库 262144-524288 桌面应用 16384-32768 结语 # 通过合理的文件描述符限制配置，可以在 系统稳定性 和 应用性能 之间取得平衡。建议定期监控文件描述符使用情况：\n# 统计各进程打开文件数 lsof -n | awk \u0026#39;{print $1}\u0026#39; | sort | uniq -c | sort -nr | head 📘 扩展阅读：Linux 内核关于文件管理的 官方文档\n","date":"2025-02-24","externalUrl":null,"permalink":"/posts/2025/linux-limits/","section":"Posts","summary":"","title":"提高Linux的文件描述符限制","type":"posts"},{"content":" 前言 # Joy-Con / Pro Controller 与主机的蓝牙配对是双向的，主机在唯一识别手柄的同时手柄也会唯一识别主机。\n如要想同一个手柄在同时双系统上使用，必须要使手柄认为这两个系统是一个系统。\n因此当我们第一次制作虚拟系统时通常不会遇到任何问题，但双系统分别升级几次后或者按了配对按钮强制重新配对后，手柄会出现只识别其中一个系统的问题。\n这里我们会使用大气层 1.5.1 新加入的 enable_external_bluetooth_db 来解决多系统手柄蓝牙连接的同步问题。\n准备工作 # 理解双系统的一些区别\nCFW(SYSNAND)\n又称真实系统，为大气层+机身 eMMC 的模式\nCFW(EMUNAND)\n破解系统\nOFW(SYSNAND)\n正版系统\n大气层 \u0026gt;= 1.5.1\n确保 sdmc:/atmosphere/config/system_settings.ini 中存在 enable_external_bluetooth_db = u8!0x1，不存在自行写入\n确保正版系统和破解系统中均已开启飞行模式\n以防万一你的真实系统没有做好屏蔽\n操作步骤 # 进入真实系统 CFW(SYSNAND)\n谨记，在真实系统下不要安装任何游戏，会造成你的正版系统的 Ban 机！\n打开 DBI，或者其他能够浏览文件的浏览器\n删除 sdmc:/atmosphere/bluetooth_devices.db\n不要动任何其他文件！\n将手柄插入主机，进入 设置-手柄与感应器-断开与手柄的连接，根据提示长按 X 断开所有手柄\n进入 手柄-更改握法/顺序 并取下手柄\n长按手柄配对键，直到手柄指示灯快速闪烁\n在取下手柄的情况下休眠主机，尝试用手柄唤醒，如果唤醒失败则从步骤 3 重复\n重启到破解系统 CFW(EMUNAND) 测试手柄是否能正常连接\n结语 # 重点就是要在 SYSNAND 配对手柄之后，通过 CFW(SYSNAND) 获取配对的手柄信息，写入 bluetooth_devices.db 中，这样就能保证在 EMUNAND 下也能正常连接手柄\n双系统配对成功后尽量不要使用配对键去重连，这样会导致手柄重新配对，需要重新进行上述操作\n","date":"2025-02-08","externalUrl":null,"permalink":"/posts/2025/nx-controller/","section":"Posts","summary":"","title":"Switch 大气层双系统手柄蓝牙配对同步","type":"posts"},{"content":" zram-generator # 安装 zram-generator\nsudo pacman -S zram-generator 修改配置，根据实际内存大小调整 zram-size\nsudo -e /etc/systemd/zram-generator.conf\n[zram0] compression-algorithm = lz4 zstd(level=1) (type=idle) zram-size = 16384 [zram1] compression-algorithm = lz4 zram-size = 32768 fs-type = ext4 mount-point = /tmpfs options = \u0026#34;noatime,discard,X-mount.mode=1777\u0026#34; 重启后 zram-generator 会自动创建 zram 设备，并将 zram1 挂载到 /tmpfs 目录\n文件系统优化 # 对于 zram 设备上的文件系统，日志等特性几乎无用，并且会占用额外的空间。\next2 没有日志，但它比 ext4 等文件系统老得多，并且有一些限制。\nbtrfs 非常现代，但他仍然有太多我们不需要的特性。\n因此我们使用无日志的 ext4 文件系统作为我们 zram 设备的文件系统。\n在 make2fs.conf 中添加新的 fs 类型，复制 ext4 配置，并删除 has_journal 选项，给新的 fs-type 起一个唯一的名字，比如 ext4withoutjournal。\nsudo -e /etc/mke2fs.conf\n[fs_types] ext4 = { features = has_journal,extent,huge_file,flex_bg,metadata_csum,64bit,dir_nlink,extra_isize } ext4withoutjournal = { features = extent,huge_file,flex_bg,metadata_csum,64bit,dir_nlink,extra_isize } zram-generator 会使用 mkfs.* 来格式化 zram 设备，因此我们需要创建一个 mkfs.ext4withoutjournal 的软链接。\nsudo ln -s /usr/bin/mke2fs /usr/bin/mkfs.ext4withoutjournal\n然后在 /etc/systemd/zram-generator.conf 中修改 fs-type 为 ext4withoutjournal。\n[zram1] compression-algorithm = lz4 zram-size = 32768 fs-type = ext4withoutjournal mount-point = /tmpfs options = \u0026#34;noatime,discard,X-mount.mode=1777\u0026#34; 重启后生效。\n性能 # 以下的性能测试非常不严谨，仅供参考\nlz4：最快，但压缩率最低 lzo：次之，压缩率稍高 zstd：最慢，压缩率最高 对于 ext4，关闭日志可以提高约 10% 的读取性能。\nReference # Arch Linux Wiki Gentoo Wiki ","date":"2024-12-19","externalUrl":null,"permalink":"/posts/2024/linux-zram/","section":"Posts","summary":"Using Zram to create a fast temporary workspace in memory","title":"Temporary Workspace with Zram","type":"posts"},{"content":" sakarie9/sway-window-switcher A Python script to help list and switch sway windows easily through Fuzzel. Python 1 0 A Python script to help list and switch sway windows easily through Fuzzel.\nRequirements # Sway A dmenu launcher, including fuzzel and rofi Python3 jq Grep Also a nerd font is required if icons not show correctly. You can change fonts in your launcher settings.\nUsage # Get sway-window-switcher.py to somewhere you can execute.\nRun sway-window-switcher.py --help to get help.\n\u0026gt; sway-window-switcher.py -h usage: sway-window-switcher.py [-h] [-t {all,floating,scratch,regular}] [--plain-output] [-l {fuzzel,rofi}] List and select windows using swaymsg and dmenu launchers like fuzzel and rofi. options: -h, --help show this help message and exit -t {all,floating,scratch,regular}, --type {all,floating,scratch,regular} Type of window to list. Defaults to \u0026#34;all\u0026#34;. --plain-output Print a plain, unbeautified list to dmenu. -l {fuzzel,rofi}, --launcher {fuzzel,rofi} Specific a dmenu launcher to use. Will use first exist launcher if not define. Bind the script to sway keybind to use it easily.\nFor example, to list all the windows in scratchpad and switch to it you can have this in sway config:\nbindsym $mod+x exec sway-window-switcher -t scratch\nMake sure sway-window-switcher is in you PATH.\nThanks to # codingotaku/fuzzel-scripts\nThis script is basically a more featured python rewrite version of codingotaku\u0026rsquo;s script.\nJas-SinghFSU/HyprPanel\nWe used the windowTitleMap from HyprPanel for a better look.\n","date":"2024-11-26","externalUrl":null,"permalink":"/posts/2024/sway-window-switcher/","section":"Posts","summary":"","title":"Sway Window Switcher","type":"posts"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/unixporn/","section":"Tags","summary":"","title":"Unixporn","type":"tags"},{"content":" GTK 2 \u0026amp; 3 # 使用 nwg-look 应用 adw-gtk3 主题\n安装所需的包 pacman -S nwg-look adw-gtk-theme\n在 nwg-look 中的组件一栏选择 adw-gtk3-dark，右侧颜色方案选择倾向暗色\n也可以根据需要设置图标主题和鼠标光标\n点击应用，保存设置\nGTK4 # 保持默认，不需要在 ~/.config/gtk-4.0/ 下进行配置\nlibadwaita # 想要使用 libadwaita 的应用，例如 nautilus，正确使用暗色，需要进行一些配置\n在 sway 下，需要安装 xdg-desktop-portal-{gtk,wlr}\n-gtk 是必须的，参考 i3/#5896\n在 Arch Linux 上，似乎并不需要上述 issue 的配置，只需要安装 xdg-desktop-portal-gtk\n正确设置环境变量\nsway wiki\n需要如下配置以正确设置环境变量\nexec systemctl --user import-environment WAYLAND_DISPLAY DISPLAY XDG_CURRENT_DESKTOP SWAYSOCK I3SOCK XCURSOR_SIZE XCURSOR_THEME ","date":"2024-11-23","externalUrl":null,"permalink":"/posts/2024/wm-gtk-theme/","section":"Posts","summary":"","title":"WM 下的 GTK 主题设置","type":"posts"},{"content":"","date":"2024-09-10","externalUrl":null,"permalink":"/tags/android/","section":"Tags","summary":"","title":"Android","type":"tags"},{"content":" Waydroid # Waydroid 的安装参考 Arch Wiki\n内核模块 # 需要带有 Binder 内核模块的内核才能运行 Waydroid。\n在 Arch Linux 上可以通过安装 linux-zen 包来满足需求。\n或者使用 DKMS 模块，参考 DKMS modules，如果安装了 linux-zen 等内核则无需安装 DKMS 模块。\n无法启动 # 如果 Waydroid 无法启动，可能是遇到了 [BUG] Waydroid is not working anymore on my Arch Linux system，需要对 waydroid-image-gapps 进行降级。\n已知的最新的可以正常运行的版本为 2024-02-17，从 SourceForge 获取。\n花屏 # Waydroid 需要使用和桌面混成同样的 GPU，当使用了不同的 GPU 时就会出现渲染错误。\n使用 waydroid-choose-gpu.sh 指定 Waydroid 使用的 GPU。\n转译 # 使用 Waydroid Script 安装转译层。\n一般在 AMD 处理器上，libndk 运行较好；Intel 处理器上 libhoudini 运行较好。\n如果出现问题可以尝试安装另一个，更换转译层之前最好将旧的转译层卸载。\n在某些游戏，如 Blue Archive 日服和国际服，会出现卡主界面/直接闪退的情况，需要对转译层二进制文件打补丁。\nlibndk # https://github.com/waydroid/waydroid/issues/788#issuecomment-2167334937\n下载 scripton_ndk.txt 重命名为 scripton_ndk.sh，并修改为可执行 sudo ./scripton_ndk.sh scripton_ndk #!/bin/bash # \u0026lt;https://github.com/waydroid/waydroid/issues/788#issuecomment-2167334937\u0026gt; function CheckHex { # file path, Ghidra offset, Hex to check commandoutput=\u0026#34;$(od $1 --skip-bytes=$(($2 - 0x101000)) --read-bytes=$((${#3} / 2)) --endian=little -t x1 -An file | sed \u0026#39;s/ //g\u0026#39;)\u0026#34; if [ \u0026#34;$commandoutput\u0026#34; = \u0026#34;$3\u0026#34; ]; then echo \u0026#34;1\u0026#34; else echo \u0026#34;0\u0026#34; fi } function PatchHex { # file path, ghidra offset, original hex, new hex file_offset=$(($2 - 0x101000)) if [ $(CheckHex $1 $2 $3) = \u0026#34;1\u0026#34; ]; then hexinbin=$(printf $4 | xxd -r -p) echo -n $hexinbin | dd of=$1 seek=$file_offset bs=1 conv=notrunc tmp=\u0026#34;Patched $1 at $file_offset with new hex $4\u0026#34; echo $tmp elif [ $(CheckHex $1 $2 $4) = \u0026#34;1\u0026#34; ]; then echo \u0026#34;Already patched\u0026#34; else echo \u0026#34;Hex mismatch!\u0026#34; fi } ndk_path=\u0026#34;/var/lib/waydroid/overlay/system/lib64/libndk_translation.so\u0026#34; if [ -f $ndk_path ]; then if [ -w ndk_path ] || [ \u0026#34;$EUID\u0026#34; = 0 ]; then PatchHex $ndk_path 0x307dd1 83e2fa 83e2ff PatchHex $ndk_path 0x307cd6 83e2fa 83e2ff else echo \u0026#34;libndk_translation is not writeable. Please run with sudo\u0026#34; fi else echo \u0026#34;libndk_translation not found. Please install it first.\u0026#34; fi libhoudini # https://github.com/waydroid/waydroid/issues/788#issuecomment-2162386712\n下载 scripton.txt 重命名为 scripton.sh，并修改为可执行 sudo ./scripton.sh scripton_ndk #!/bin/bash function CheckHex { #file path, Ghidra offset, Hex to check commandoutput=\u0026#34;$(od $1 --skip-bytes=$(($2 - 0x100000)) --read-bytes=$((${#3} / 2)) --endian=little -t x1 -An file | sed \u0026#39;s/ //g\u0026#39;)\u0026#34; if [ \u0026#34;$commandoutput\u0026#34; = \u0026#34;$3\u0026#34; ]; then echo \u0026#34;1\u0026#34; else echo \u0026#34;0\u0026#34; fi } function PatchHex { #file path, ghidra offset, original hex, new hex file_offset=$(($2 - 0x100000)) if [ $(CheckHex $1 $2 $3) = \u0026#34;1\u0026#34; ]; then hexinbin=$(printf $4 | xxd -r -p) echo -n $hexinbin | dd of=$1 seek=$file_offset bs=1 conv=notrunc tmp=\u0026#34;Patched $1 at $file_offset with new hex $4\u0026#34; echo $tmp elif [ $(CheckHex $1 $2 $4) = \u0026#34;1\u0026#34; ]; then echo \u0026#34;Already patched\u0026#34; else echo \u0026#34;Hex mismatch!\u0026#34; fi } houdini_path=\u0026#34;/var/lib/waydroid/overlay/system/lib64/libhoudini.so\u0026#34; if [ -f $houdini_path ]; then if [ -w houdini_path ] || [ \u0026#34;$EUID\u0026#34; = 0 ]; then PatchHex $houdini_path 0x4062a5 48b8fbffffff 48b8ffffffff PatchHex $houdini_path 0x4099d6 83e0fb 83e0ff PatchHex $houdini_path 0x409b42 e8892feeff 9090909090 else echo \u0026#34;Libhoudini is not writeable. Please run with sudo\u0026#34; fi else echo \u0026#34;Libhoudini not found. Please install it first.\u0026#34; fi ","date":"2024-09-10","externalUrl":null,"permalink":"/posts/2024/waydroid-issues/","section":"Posts","summary":"","title":"Waydroid 疑难排解","type":"posts"},{"content":"如何使用 FFmpeg 将音频文件转换为 Opus，以及转换过程中遇到的各种坑。\n听不出来就是无损！\n背景 # TL;DR! 可以直接跳到 脚本\n近来手机和 NAS 存储空间逐渐不够用了，在想办法处理那些 WAV 文件，将其转换为 FLAC 以压缩空间的时候，想到了 Opus 这个效率很高的编码格式。\n虽然把所有无损音频直接转换为有损音频保存收藏不可取，但把手机内保存的音乐统统使用压缩率更好的格式是一个不错的尝试。\n首先介绍一下本篇的主角：Opus\nOpus是一个有损音频压缩的数字音频编码格式，由Xiph.Org基金会开发。Opus集成了两种声音编码的技术：以语音编码为导向的SILK和低延迟的CELT。Opus可以无缝调节高低比特率。在编码器内部它在较低比特率时使用线性预测编码在高比特率时候使用变换编码（在高低比特率交界处也使用两者结合的编码方式）。Opus具有非常低的算法延迟（默认为22.5 ms）[5]，非常适合用于低延迟语音通话的编码，像是网络上的即时声音流、即时同步声音旁白等等，此外Opus也可以透过降低编码比特率，达成更低的算法延迟，最低可以到5 ms。在多个听觉盲测中，Opus都比MP3、AAC、HE-AAC等常见格式，有更低的延迟和更好的声音压缩率。\n总之就是非常现代化的一种编码格式，能够在低码率下保持极高的清晰度（与同码率的 MP3 相比）；在中等的码率下（96kbps-128kbps 左右）能够做到接近无损的听感；在更高的码率下（160kbps-192kbps）几乎可以认为无损。\n听觉测试 # 在调查是否应该选用 Opus 时，进行了一些简单的听觉测试，选取了两首电吉他声占主导且非常清晰的音乐作为样本。\n本测试仅娱乐，非常不科学\n1 2 3 4 A 96k-opus 320k-mp3 192k-mp3 160k-opus B 160k-opus 128k-mp3 320k-mp3 96k-opus A 组的样本均由 FLAC 转换而来，B 组的样本均由 B3 的 320kbps 的 MP3 转换而来。\n以 MP3 为源文件是为了测试从有损到有损的转换过程中会丢失多少细节，也就是所谓的 “Generation loss” 有多严重。\n测试结论 # 甲：完全听不出来\n乙：A3＞A2＞A4＞A1，A1、A4、B1、B4 有点糊，事后又添加了 320k-opus 的 A5，依然糊，推测可能是设备的解码器存在问题\n丙：A3 最清楚，A4 最糊\n虽然测试非常之不严谨，但我们也能看出来至少 192k-mp3 和 320k-mp3 大家都是分不出来的。\n因为测试所用的网站是临时搓出来的，乙和丙的设备上只有 MP3 格式的样本会显示音频时长，Opus 的样本似乎是串流过去的，这会对音质造成多少影响暂时存疑。\n但总之，个人是完全听不出来 96k-opus 和 320k-mp3 的区别的。所以转码策略就是：存在无损文件的，转为 128kbps 或者 160kbps 的 Opus；源文件只有有损的，统统转为 96kbps Opus。\n这里引用一句话：\nSubjectively, though, if you can\u0026rsquo;t hear the difference, then by definition there was no quality loss, which is the whole point of these codecs: fooling you in that way.\n编写脚本 # 使用 FFmpeg 进行音频转码理论上是完全没有难度的，ffmpeg -i input.flac output.opus 理论上就能直接完成了。\nしかし、\nだが、\nButt、\n这其中存在着很多很多的坑，下面我们从头开始一步步踏进每一个坑。\n多线程并行 # 众所周知，FFmpge 是没有内置的同时处理多文件、或者利用多核心的方式的，在我们处理上千个音频文件的时候会非常非常慢。\n所以我们需要用 GNU Parallel 吃满 CPU，一个简单的用法如下。\nfind . -type f -name \u0026#34;*.flac\u0026#34; | parallel ffmpeg -i {} {.}.opus 将当前目录下的 FLAC 转换为 Opus，乍一看是没问题的，他也确实可以工作。\n但是其存在一个非常严重的问题，目前 FFmpeg 不支持 OGG/Opus 文件的专辑封面写入。\n专辑封面 # 此事在 #4448 Support writing album cover art image embedded in ogg / opus metadata 中亦有记载。\n很难想象一个九年前就存在的问题直到今日依然未解决。\n就跟上述 Issue 描述的一样，FFmpeg 无法为 Opus 文件嵌入专辑封面，所以我们需要另辟蹊径。\n经过一番搜索，发现了使用 opusenc 命令进行转换可以保留所有的元数据以及专辑封面。\n简单用法如下：\nffmpeg -i input.mp3 -f flac - | opusenc - output.opus 将 MP3 先转为 FLAC，再通过管道由 opusenc 转为 Opus，这样就跳过了 FFmpeg 直接转为 Opus 的过程。\n不直接使用 opusenc 的原因是他只支持几种格式：The input format can be Wave, AIFF, FLAC, Ogg/FLAC, or raw PCM.，所以如果需要转换 MP3 到 Opus 时需要先转为 FLAC。\n然后这种方式由引入了一个新的问题，有些文件转换为 Opus 后，体积甚至比原来的 MP3 大上了 50%！\n经过研究，发现多出来的大小来自专辑封面。似乎 FFmpeg 在将源文件转为 FLAC 的时候顺手将专辑封面也处理了。\n原本 MP3 内嵌的 3000x3000 785.4kB JPEG 的专辑封面，转换到 Opus 之后，内嵌封面变成了 3000x3000 12.0MB PNG。\n这导致体积从原来的 8.1MB 暴涨到了 23.5MB，本来就是为了节省空间才进行的转码，这显然是不可接受的。\n想要转码时不处理封面，需要使用 -c:v copy，修改后的命令如下：\nffmpeg -i input.mp3 -c:v copy -f flac - | opusenc - output.opus 这样就能做到从 MP3 到 Opus 的转码了，除此之外还存在着源文件内的封面就已经很大的情况，我们暂且按下不表，在后续步骤处理。\n结构化输出 # 为了将源文件转换后输出到指定的目标目录，需要对目录进行一些拼接。\n但是问题来了，我在这里遇到了许多乱七八糟的引号嵌套问题，总之直接放解决的输出的脚本在这里。\nconvert_to_opus() { input_file=$1 relative_path=\u0026#34;${input_file#\u0026#34;$SOURCE_DIR\u0026#34;/}\u0026#34; output_file=\u0026#34;$DEST_DIR/${relative_path%.*}.opus\u0026#34; # 已存在则跳过 if [ -f \u0026#34;output_file\u0026#34; ]; then return 0; fi # 创建输出文件所在的目录 output_file_dir=$(dirname \u0026#34;$output_file\u0026#34;) mkdir -p \u0026#34;$output_file_dir\u0026#34; # -c:v copy is REQUIRED as FFmpeg will convert the album cover, cause extremely large files ffmpeg -hide_banner -loglevel warning -i \u0026#34;$input_file\u0026#34; -c:v copy -f flac - | opusenc --quiet --bitrate 128 - \u0026#34;$output_file\u0026#34; } # IMPORTANT export -f convert_to_opus find \u0026#34;$SOURCE_DIR\u0026#34; -type f -name \u0026#34;*.flac\u0026#34; | parallel --progress convert_to_opus 将 parallel 的 command 换成函数能避免使用字符串传命令造成的 globbing and word splitting 问题。\n不要忘了 export -f 命令，否则 parallel 无法识别函数。\n到这里已经差不多能用了，我们还有最后一个问题需要解决。\n专辑封面压缩 # 专辑封面压缩。\n为什么要压缩呢，举个例子，对于 100M 的 FLAC 而言，5M 的专辑封面只占其体积的 5%，不是什么大事，不缺这点体积。\n但是我们为了压榨空间把他转为 Opus 后，专辑封面占的空间相比实际音频就大的难以接受了，100M 的 FLAC 转为 Opus 后音频部分仅有 8M 左右，如果直接将封面嵌进去，8+5=13M 的音频文件里 40% 的体积都用来存图片了，显然是非常不合理的。\n因此我们要在嵌入之前对专辑封面进行一次压缩，音频都压了不缺这点质量损失。\n首先我们的流程是：从源文件提取出专辑封面 -\u0026gt; 压缩 -\u0026gt; 将源文件的音频部分和压缩后的封面合并转换为 FLAC（原因如上） -\u0026gt; 使用 opusenc 转为 opus。\n得到了下面的命令\nffmpeg -i \u0026#34;$input_file\u0026#34; -an -vcodec copy -f image2pipe - | ffmpeg -i - -vf \u0026#34;scale=\u0026#39;if(gt(iw,1000),1000,iw)\u0026#39;:-1\u0026#34; \u0026#34;$cover_convert_file\u0026#34; # 转换并嵌入封面 ffmpeg -i \u0026#34;$input_file\u0026#34; -i \u0026#34;$cover_convert_file\u0026#34; -map 0:a -map 1:v -c:v copy -disposition:v attached_pic -metadata:s:v comment=\u0026#34;Cover (front)\u0026#34; -f flac - | opusenc - \u0026#34;$output_file\u0026#34; 其中 -vf \u0026quot;scale='if(gt(iw,1000),1000,iw)':-1\u0026quot; 是将专辑封面大于 1000x 的缩小到 1000x，小于 1000x 的不变。\n-map 0:a -map 1:v -c:v copy -disposition:v attached_pic -metadata:s:v comment=\u0026quot;Cover (front)\u0026quot; 这一串都是写入专辑封面的。\n注意到其中我们引入了一个中间文件 $cover_convert_file，在并行中需要使用合适的路径避免多线程同时读写一个文件造成的冲突，这里将中间文件使用源文件的目录结构和文件名放在临时文件目录中避免冲突。\n变量导出 # 到这里脚本差不多已经完成了，但是还有一个问题，在函数中使用变量时需要提前导出变量。\n在上面的 convert_to_opus() 中使用了 SOURCE_DIR 变量，这样就需要在函数中先进行导出，否则函数内此变量不存在就会为空。\n要在下面的 parallel 中调用的函数也需要用 export -f 导出\nexport SOURCE_DIR export DEST_DIR convert_to_opus() { input_file=$1 relative_path=\u0026#34;${input_file#\u0026#34;$SOURCE_DIR\u0026#34;/}\u0026#34; } export -f convert_to_opus 完整脚本 # 将 source_path 中的所有 .flac,.mp3,.wav 转为 .opus，放入 dest_path 中。\n./converter.sh -b 128 source_path dest_path\n#!/bin/bash show_help() { echo \u0026#34;Usage: $0 [-b 96] [-c] SOURCE_PATH DEST_PATH\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;Options:\u0026#34; echo \u0026#34; -b Opus Bitrate. E.g. -b 96, -b 128. Default is 96.\u0026#34; echo \u0026#34; -c --audio-only If copy other files in the source directory.\u0026#34; echo \u0026#34; -h, --help Show this help message and exit.\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;Arguments:\u0026#34; echo \u0026#34; SOURCE_PATH Path to the directory containing files needs to be converted.\u0026#34; echo \u0026#34; DEST_PATH Path to the directory to save the converted files.\u0026#34; } # 初始化变量 BITRATE=96 CACHE_DIR=\u0026#34;/tmp/opus-convert\u0026#34; AUDIO_ONLY=false # 解析命令行选项 while getopts \u0026#34;:b:ch-:\u0026#34; opt; do case \u0026#34;${opt}\u0026#34; in b) BITRATE=${OPTARG} ;; c) AUDIO_ONLY=true ;; h) show_help exit 0 ;; -) case \u0026#34;${OPTARG}\u0026#34; in audio-only) AUDIO_ONLY=true ;; help) show_help exit 0 ;; *) echo \u0026#34;Invalid option: --${OPTARG}\u0026#34; \u0026gt;\u0026amp;2 exit 1 ;; esac ;; \\?) echo \u0026#34;Invalid option: -$OPTARG\u0026#34; \u0026gt;\u0026amp;2 exit 1 ;; :) echo \u0026#34;Option -${OPTARG} requires an argument.\u0026#34; \u0026gt;\u0026amp;2 exit 1 ;; esac done # 移除已处理的选项参数 shift $((OPTIND - 1)) # 检查参数是否足够 if [ $# -ne 2 ]; then echo \u0026#34;Error: SOURCE_PATH and DEST_PATH are required.\u0026#34; show_help exit 1 fi # 获取参数 SOURCE_DIR=\u0026#34;${1%/}\u0026#34; DEST_DIR=\u0026#34;${2%/}\u0026#34; # 检查源目录是否存在 if [ ! -d \u0026#34;$SOURCE_DIR\u0026#34; ]; then echo \u0026#34;Error: Source directory does not exist.\u0026#34; exit 1 fi # 创建目标目录（如果不存在） mkdir -p \u0026#34;$DEST_DIR\u0026#34; # 导出环境变量 export SOURCE_DIR export DEST_DIR export BITRATE export CACHE_DIR convert_to_opus_compress_cover() { input_file=$1 # 计算输出文件的路径 relative_path=\u0026#34;${input_file#\u0026#34;$SOURCE_DIR\u0026#34;/}\u0026#34; output_file=\u0026#34;$DEST_DIR/${relative_path%.*}.opus\u0026#34; # 缓存 cover_convert_file=\u0026#34;$CACHE_DIR/${relative_path%.*}.jpg\u0026#34; mkdir -p \u0026#34;$(dirname \u0026#34;$cover_convert_file\u0026#34;)\u0026#34; # 已存在则跳过 if [ -f \u0026#34;output_file\u0026#34; ]; then return 0; fi # 创建输出文件所在的目录 output_file_dir=$(dirname \u0026#34;$output_file\u0026#34;) mkdir -p \u0026#34;$output_file_dir\u0026#34; # 提取并压缩封面 ffmpeg -hide_banner -loglevel warning -i \u0026#34;$input_file\u0026#34; -an -vcodec copy -f image2pipe - | ffmpeg -hide_banner -loglevel warning -i - -vf \u0026#34;scale=\u0026#39;if(gt(iw,1000),1000,iw)\u0026#39;:-1\u0026#34; \u0026#34;$cover_convert_file\u0026#34; # 转换并嵌入封面 ffmpeg -hide_banner -loglevel warning \\ -i \u0026#34;$input_file\u0026#34; -i \u0026#34;$cover_convert_file\u0026#34; -map 0:a -map 1:v -c:v copy -disposition:v attached_pic -metadata:s:v comment=\u0026#34;Cover (front)\u0026#34; -f flac - | opusenc --quiet --bitrate \u0026#34;$BITRATE\u0026#34; - \u0026#34;$output_file\u0026#34; # 清理缓存 rm \u0026#34;$cover_convert_file\u0026#34; } export -f convert_to_opus_compress_cover find \u0026#34;$SOURCE_DIR\u0026#34; -type f -name \u0026#34;*.flac\u0026#34; -o -name \u0026#34;*.mp3\u0026#34; -o -name \u0026#34;*.wav\u0026#34; | parallel --progress convert_to_opus_compress_cover # 复制其他文件到目标目录 if [ $AUDIO_ONLY = false ]; then rsync -a --include=\u0026#39;*/\u0026#39; --include=\u0026#39;*.lrc\u0026#39; --include=\u0026#39;*.jpg\u0026#39; --include=\u0026#39;*.png\u0026#39; --include=\u0026#39;*.webp\u0026#39; --exclude=\u0026#39;*\u0026#39; \u0026#34;$SOURCE_DIR/\u0026#34; \u0026#34;$DEST_DIR/\u0026#34; fi ","date":"2024-08-31","externalUrl":null,"permalink":"/posts/2024/ffmpeg-opus/","section":"Posts","summary":"如何使用 FFmpeg 将音频文件转换为 Opus，以及转换过程中遇到的各种坑","title":"使用 FFmpeg 转换音频为 Opus：避坑指南与实战经验","type":"posts"},{"content":"购买作品时，1点数=1 JPY，可用于支付。\n前言 # DLsite 目前提供的点数购入网站一共有下面几种：\nDianshu.JP\n支持支付宝\n汇率较高\nDLPay\n支持绑定了银联的 PayPal 账户 For Books\n大概只支持境外卡（未测试） 汇率陷阱 # Dianshu # Dianshu 作为 DLsite 官方推荐的中国大陆的支付方式，自然是最方便的，但是相对的其汇率较高\n站内给出的预估汇率为大概 1000JPY \u0026lt;-\u0026gt; 53RMB （未实际购买不确定是否为最终结算汇率）\n作为参考，本日（2024-08-12）的汇率为 1000JPY \u0026lt;-\u0026gt; 48.53RMB，足足贵出 5%。\n因此在拥有其他支付方式时不建议直接使用 Dianshu\nDLPay # DLPay 的购买要求输入电子邮箱，之后会往邮箱内发送一封包括购买点数购买链接的邮件，点击链接并登录 Paypal 后进入付款方式选择的界面\n可以看到此时的汇率为 1000JPY \u0026lt;-\u0026gt; 51.21RMB，比 Dianshu 便宜一些，但仍比汇率贵上不少\n点击 查看汇率选项，将币种改为 JPY\n这样会使用发卡组织的汇率结算，而非 Paypal 提供的汇率结算\n最终实际支付 49.03RMB，跟汇率非常接近\n总结 # 购买 DLsite 点数时使用 DLPay 并修改 Paypal 此次购物使用的币种为 JPY\n","date":"2024-08-12","externalUrl":null,"permalink":"/posts/2024/dlsite-202408/","section":"Posts","summary":"","title":"记一次 DLsite 点数购物","type":"posts"},{"content":" 前言 # 罗技的某些鼠标 （G502、G903）的滚轮，存在步进/无极滚动两种模式，在 Linux 下，步进模式的滚轮会出现滚一下、动两格的情况\n这个问题虽然在浏览器等场景不太明显，滚动可能只会导致几个像素的差异，但在终端中的滚动往往会偏移几行，或者在音乐播放器中通过滚动调整音量，基本上永远都没法滚动到想要的音量上\n在 Minecraft 中问题就更严重了，滑动滚轮会来回在几个快捷栏之间跳动，想要准确利用滚轮滚动到目标快捷栏会非常恼人\n解决方案 # 相关的讨论：\nMouse scrolling behaves oddly on wayland\nHID++ Logitech G903 generates full scroll wheel events with every hi-res tick when attached via USB\nTL;DR\n这个问题是由内核模块 hid_logitech_dj 和 hid_logitech_hidpp 所造成的\n使用以下命令临时禁用这两个模块：sudo rmmod hid_logitech_dj hid_logitech_hidpp\n如果确实有用，进行如下步骤永久禁用模块\n新建文件 /etc/modprobe.d/99-custom-no-logitech-driver.conf\n在文件中添加以下两行\nblacklist hid_logitech_dj blacklist hid_logitech_hidpp 重新插拔无线接收器 注意，禁用掉这两个模块后，能修改鼠标配置的程序（如 Piper 等），将会无法使用，确保配置完成之后再进行以上操作\n","date":"2024-08-12","externalUrl":null,"permalink":"/posts/2024/logitech-linux/","section":"Posts","summary":"","title":"罗技鼠标无线模式下在 Linux 里的滚轮问题","type":"posts"},{"content":"在 tmux 中进行 Arch Linux 的滚动更新\n前言 # 在 tmux 中进行滚动更新，比直接在终端中直接滚动有着更多好处：\n防止更新过程中误关闭终端 更新后关闭终端也能重新连接回去查看更新日志 但是如果不是重度 tmux 用户，更新前手动进入 tmux 再更新显得有些繁琐\n因此本文提出一个在普通终端下直接唤起 tmux 并运行更新命令的脚本，此脚本有以下特点：\n在终端内运行脚本，如果对应的 Session 不存在，则新建一个 tmux Session 并运行命令 如果对应的 Session 已经存在，则直接运行命令，并连接回此 Session 如果已经在 tmux 内，直接运行命令 graph LR A[运行脚本] B[Attach tmux Session] BN[New tmux Session] C[Command] A -- Session 不存在 --- BN A -- Session 存在 --- B A -- 已经在Session中 --- C B --\u003e C BN --\u003e C 使用 # 其中的 zsh 是为了在命令运行完毕后不退出，根据自己使用的替换成 bash 等 Shell\n#!/usr/bin/env bash session_name=\u0026#34;paru\u0026#34; cmd=\u0026#34;paru -Syu\u0026#34; # 检查是否存在的tmux session if tmux has-session -t $session_name 2\u0026gt;/dev/null; then # 检查是否在tmux内 if [ -n \u0026#34;$TMUX\u0026#34; ]; then # 在 tmux 内 bash -c \u0026#34;$cmd\u0026#34; else # 不在 tmux 内，则连接到此session并运行命令 tmux send-keys -t $session_name \u0026#34;$cmd\u0026#34; Enter tmux attach-session -t $session_name fi else # 如果不存在，则新建session并运行命令 tmux new-session -s $session_name \u0026#34;${cmd}; zsh\u0026#34; fi ","date":"2024-05-07","externalUrl":null,"permalink":"/posts/2024/pacman-in-tmux/","section":"Posts","summary":"","title":"在 tmux 中进行 Arch Linux 的滚动更新","type":"posts"},{"content":"在 Linux 上 使用 Steamcommunity 302 并使用 systemd 实现开机自启\n配置 # 根据需要勾选所需的功能\nchmod +x Steamcommunity_302 ./Steamcommunity_302 测试 # chmod +x steamcommunity_302.cli sudo ./steamcommunity_302.cli 测试是否能正常访问 steam 及社区\n自启 # 修改路径\n# /etc/systemd/system/steamcommunity-302.service [Unit] Description=Steamcommunity_302 Steam Reverse Proxy After=network-online.target Wants=network-online.target [Service] WorkingDirectory=/path_to_302/Steamcommunity_302 ExecStart=/path_to_302/Steamcommunity_302/steamcommunity_302.cli [Install] WantedBy=multi-user.target 然后启动\nsystemctl enable --now steamcommunity-302.service v13 已经原生支持 Linux，以下为旧版本配置 在 Linux 上 使用 Caddy 原生实现 Steamcommunity 302 的功能并实现开机自启\n以下操作均在 Arch Linux 下进行，其他发行版可能需要适当修改证书安装的路径及所用命令 生成配置文件 # 为了生成自定义配置，需要在 Wine 下运行 Steamcommunity302，在设置里勾选需要的服务，将证书期限修改为 10 年，点击 导出SteamDeck版本一键安装脚本\n在 SteamDeck_302 文件夹下将如下几个文件到任意目录，这里假定为 /data/caddy，根据需要自行替换目录\nsteamcommunity.crt steamcommunity.key steamcommunity_302.caddy.json steamcommunityCA.pem 复制 Steamcommunity 302 设置里的 hosts 到 Linux 的 /etc/hosts，根据反代服务选择不同，hosts 条目也不同，请复制自己设置内的 hosts\n127.0.0.1 steamcommunity.com #S302 127.0.0.1 www.steamcommunity.com #S302 127.0.0.1 store.steampowered.com #S302 127.0.0.1 checkout.steampowered.com #S302 127.0.0.1 api.steampowered.com #S302 127.0.0.1 help.steampowered.com #S302 127.0.0.1 login.steampowered.com #S302 127.0.0.1 store.akamai.steamstatic.com #S302 下载 Caddy # 在 caddy/release 下载对应平台的 caddy（如 amd64 下载 caddy_2.7.6_linux_amd64.tar.gz ）\n解压出来 caddy 二进制文件放入 /data/caddy\n此时你的 /data/caddy 文件夹结构应如下\ncaddy ├── caddy ├── steamcommunity_302.caddy.json ├── steamcommunityCA.pem ├── steamcommunity.crt └── steamcommunity.key 编辑配置 # 目前使用SteamDeck版本一键安装脚本则无需修改，请略过本节 打开 steamcommunity_302.caddy.json\n找到随机生成的端口号，此处端口为 19736\nhttps://steamcommunity.com:19736 https://www.steamcommunity.com:19736 { tls steamcommunity.crt steamcommunity.key @steamcommunityrp { path /comment/* path /forum/* ··· https://store.steampowered.com:19736 https://api.steampowered.com:19736 https://help.steampowered.com:19736 https://login.steampowered.com:19736 https://store.akamai.steamstatic.com:19736 { #tls self_signed tls steamcommunity.crt steamcommunity.key ··· 将所有的 :19736 删除，处理后的部分如下\nhttps://steamcommunity.com https://www.steamcommunity.com { tls steamcommunity.crt steamcommunity.key @steamcommunityrp { path /comment/* path /forum/* ··· https://store.steampowered.com https://api.steampowered.com https://help.steampowered.com https://login.steampowered.com https://store.akamai.steamstatic.com { #tls self_signed tls steamcommunity.crt steamcommunity.key ··· 安装证书 # certutil -A -d sql:~/.pki/nssdb -n \u0026#34;Steamcommunity302\u0026#34; -t C,, -i \u0026#34;steamcommunityCA.pem\u0026#34; sudo cp steamcommunityCA.pem /etc/ca-certificates/trust-source/anchors/steamcommunityCA.crt sudo trust extract-compat 启动服务 # 赋予 caddy 可执行权限\nchmod +x caddy 赋予 caddy 监听所需端口权限\nsudo setcap CAP_NET_BIND_SERVICE=+eip caddy 启动\n./caddy run --config steamcommunity_302.caddy.json --adapter caddyfile 如启动无报错 Ctrl+C 强行停止，配置 Systemd 服务\n新建编辑 .config/systemd/user/caddy.service，修改两处 /data/caddy\n[Unit] Description=Caddy Steam Reverse Proxy [Service] WorkingDirectory=/data/caddy ExecStart=/data/caddy/caddy run --config steamcommunity_302.caddy.json --adapter caddyfile [Install] WantedBy=default.target 运行并启动服务\nsystemctl --user daemon-reload systemctl --user enable --now caddy.service 查看服务状态\nsystemctl --user status caddy.service 疑难解答 # steamcommunity_302.caddy.json 不存在？ steamcommunity 302 未成功运行，尝试在 windows 环境下重新运行 ","date":"2024-05-07","externalUrl":null,"permalink":"/posts/2024/steam-caddy/","section":"Posts","summary":"在 Linux 上 使用 Steamcommunity 302 并使用 systemd 实现开机自启","title":"在 Linux 上反代 Steam 社区","type":"posts"},{"content":"通过代理访问家中拥有公网 IP 的 NAS\n前言 # 众所周知，直接在拥有公网 IP 的家宽上开放 80,443 等端口是可能会被运营商查水表的。但当用户拥有大量内网服务时，记端口是个大问题，我们需要一种能直接通过域名访问内网服务，且出门在外时使用手机也能访问到内网服务的方案\n因此，我们将使用 ShadowSocks 作为连回内网的桥梁，使用 Caddy 为内网服务提供反向代理。这种方式有以下几个优点：\n无感：在实际使用中用户直接使用域名访问服务 快速：与 frp 转发等方案相比，用户与服务直连，不会被云服务器带宽卡脖子 扩展性高：添加了新服务后只需修改 Caddy 配置即可立即使用 但是同时也带来了一些问题：\n配置稍加繁琐：用户端需要配置 Clash 等能够链接 ShadowSocks 的软件 硬性要求公网 IP 要求 # 具有公网 IP 的家宽 接入宽带的 Linux 设备 可以使用 Clash 接入网络的终端 支持 DDNS 及通配符解析的域名 配置 # 准备 # 首先确定需要访问的服务的 IP 及端口，例如在内网中运行的 EMBY Server、Qbittorrent、PVE 等服务，接下来将会以这些服务作为例子\nEMBY Server: 192.168.50.254:8096 Qbittorrent: 192.168.50.254:8081 PVE: 192.168.50.10:8006 本例中将使用域名 example.com 作为例子进行域名配置，域名托管在 cloudflare 上\n配置 DNS # 使用 DDNS 解析工具进行家宽 IP 的固定解析，例如 ddns-go，将 IP 解析到 a.example.com 上，具体操作步骤参考 ddns 工具文档\n将 *.a.example.com 解析到 Caddy 所在的地址上，例如 192.168.50.254\n获取 cloudflare 的 API Token\n进入 API Tokens 页面，点击 Create Token 按钮，再点击 Get started，填写 Token name，在 Permissions 中添加两个权限：\nZone / Zone / Read Zone / DNS / Edit 配置完成后记下 Token，配置 Caddy 时需要用到\n配置 Caddy # 在内网中的服务器上配置 Caddy 服务，最好在上述的 EMBY 等流量可能会很大的服务的同一台服务器上配置，同时需要此服务器的 80,443 端口可供内网访问，但无需对外网开放。将要配置 Caddy 的服务器的 IP 例为 192.168.50.254\n编译镜像 # 由于本文使用 Cloudflare 托管域名，需要使用具有 Cloudflare 模块的 Caddy 进行证书的配置，首先编写 Dockerfile：\nFROM caddy:2.7-builder AS builder RUN xcaddy build \\ --with github.com/caddy-dns/cloudflare FROM caddy:2.7 COPY --from=builder /usr/bin/caddy /usr/bin/caddy 在 Dockerfile 所在的目录下运行 docker build --tag=caddy-cf . 编译镜像\n配置 Caddyfile # 根据自己服务填写 Caddyfile，将上面得到的 cloudflare API Token 填入配置中\n{ http_port 80 https_port 443 } *.a.example.com { tls { dns cloudflare YOUR_API_TOKEN_HERE } } https://emby.a.example.com { reverse_proxy 192.168.50.254:8096 } https://qbit.a.example.com { reverse_proxy 192.168.50.254:8081 } https://pve.a.example.com { reverse_proxy 192.168.50.10:8006 { transport http { tls_insecure_skip_verify } } } 启动 Caddy # 完成后启动 Caddy，注意需要 --cap-add=NET_ADMIN，以及 80,443 端口未被其他应用占用\ndocker run -d --cap-add=NET_ADMIN --name=caddy --restart=always \\ -v \u0026#34;$PWD\u0026#34;/Caddyfile:/etc/caddy/Caddyfile \\ -v \u0026#34;$PWD\u0026#34;/data:/data \\ --network=host \\ caddy-cf 完成后此时使用内网设备应该已经能使用 https://emby.a.example.com 等在 Caddy 中配置过的域名访问对应服务了，但是因为 *.a.example.com 解析到了一个内网地址，所以无法从公网访问\n配置 ShadowSocks # 和 Caddy 同理，因为流量会经过 ShadowSocks 进行转发，所以尽量将 ShadowSocks 安装在大流量服务的同一服务器上\n安装 shadowsocks-rust\n在 /etc/shadowsocks-rust/server.json 中填写以下内容\n{ \u0026#34;server\u0026#34;: \u0026#34;0.0.0.0\u0026#34;, \u0026#34;server_port\u0026#34;: 51888, \u0026#34;password\u0026#34;: \u0026#34;YOUR_PASSWORD_HERE\u0026#34;, \u0026#34;timeout\u0026#34;: 300, \u0026#34;method\u0026#34;: \u0026#34;chacha20-ietf-poly1305\u0026#34;, \u0026#34;dns\u0026#34;: \u0026#34;google\u0026#34; } 建议使用 ssservice genkey -m \u0026quot;chacha20-ietf-poly1305\u0026quot; 生成较强的密码\n启动 ShadowSocks 服务 systemctl enable --now shadowsocks-rust-server@server.service\nShadowSocks 所需要的端口可以任意指定，但需要在后面的步骤中配置端口转发且暴露至公网，建议使用随机高端口号以及较强的密码保证安全\n端口转发 # 在内网主路由器上配置端口转发，配置方法根据路由品牌各有不同。\n以华硕为例，进入 外部网络-端口转发-添加设置文件\n外部端口填写任意端口，后续配置 Clash 时需要这个端口以连接 ShadowSocks 服务 内部端口填写上述的 ShadowSocks 配置文件中的 server_port 本地 IP 地址填写 SHadowSocks 服务所在的服务器内网 IP 本例中为\n外部端口 内部端口 本地 IP 地址 通信协议 51888 51888 192.168.50.254 BOTH 这样理论上就能通过 路由器公网IP:51888 端口访问 ShadowSocks 服务了；由于我们已经配置了 DDNS，所以也能通过 a.example.com:51888 端口访问 ShadowSocks 服务\n配置 Clash # 在需要在外网访问内网的设备上配置 Clash 客户端\n在 Clash 配置文件中添加如下配置\nproxies: - name: \u0026#34;NAS\u0026#34; type: ss server: a.example.com port: 51888 cipher: chacha20-ietf-poly1305 password: \u0026#34;YOUR_PASSWORD_HERE\u0026#34; rules: - DOMAIN-SUFFIX,a.example.com,NAS 或者如果想要在内网环境下不流量经过 ShadowSocks，直接使用直连，可以使用如下配置\nproxies: - name: \u0026#34;NAS\u0026#34; type: ss server: a.example.com port: 51888 cipher: chacha20-ietf-poly1305 password: \u0026#34;YOUR_PASSWORD_HERE\u0026#34; proxy-groups: - { name: HOME, type: fallback, proxies: [DIRECT, NAS], url: \u0026#34;https://test.a.example.com\u0026#34;, interval: 3600, } rules: - DOMAIN-SUFFIX,a.example.com,HOME 内网下 test.a.example.com 指向 192.168.50.254，url-test 时连通，所以 a.example.com 会走 DIRECT 直连\n外网环境下不连通，a.example.com 的流量会分流到 NAS 规则下，经过 ShadowSocks 转发至内网中\n测试 # 至此配置完成，使用终端测试连接，在开启了 Clash 后，访问 emby.a.example.com 应能正常连接，且拥有完整的 TLS 加密\n","date":"2024-05-05","externalUrl":null,"permalink":"/posts/2024/network-home/","section":"Posts","summary":"","title":"安全便利地访问家里的 NAS","type":"posts"},{"content":" 本篇为 https://ejmastnak.com/tutorials/arch/caps2esc 的整理与翻译 前言 # 目标 # 使用 caps2esc ，让 Caps Lock 键在单独按下时充当 Escape 键，在与其他键组合按下时充当 Control 键。\n动机 # 愉快、符合人体工程学，系统范围地将 Caps Lock 映射为非常有用的 Escape 和 Control 键，以及拥有更好的 Vim 或 Emacs 体验。\n参考 # caps2esc GitLab 页面 Ask Ubuntu: 如何安装 caps2esc？ 介绍 # caps2esc 实用程序允许您在 libevdev 库级别将 Caps Lock 重新映射到 Escape 和 Control。因为 libevdev 相对底层——仅高于操作系统内核——所以此解决方案除了图形环境外，还适用于纯 Linux 控制台。\n安装使用 # 安装 # 从 Arch 仓库安装 caps2esc 包：\n# Install caps2esc sudo pacman -S interception-caps2esc 这还会将 interception-tools 包作为依赖项进行安装。 interception-tools 包含一个名为 udevmon 的输入设备监视程序，我们将使用它来捕获 Caps Lock 和 Escape。\n配置 # 创建配置文件 /etc/udevmon.yaml （如果不存在），并在其中添加以下配置：\n- JOB: \u0026#34;intercept -g $DEVNODE | caps2esc | uinput -d $DEVNODE\u0026#34; DEVICE: EVENTS: EV_KEY: [KEY_CAPSLOCK, KEY_ESC] 说明（点击展开）\n此 udevmon 作业在按下 Caps Lock 和 Escape 键（由名称 KEY_CAPSLOCK 和 KEY_ESC 标识）时运行 shell 命令 intercept -g $DEVNODE | caps2esc | uinput -d $DEVNODE ；udevmon 将根据需要将 $DEVNODE 变量设置为匹配设备的路径（ /dev 目录中的某个虚拟文件）。\nshell 命令使用 intercept 程序获取 Caps Lock 或 Escape 键的输入设备，将键事件管道传输到 caps2esc 程序（该程序实现 Caps Lock 到 Escape/Control 逻辑），然后使用 uinput 将处理后的输出管道传输回虚拟键设备。（你可以阅读 Interception Tools/How it works 以了解详细信息。）\nTip：上述 udevmon 配置将使 Caps Lock 作为 Escape 和 Control 键工作，并将 Escape 键作为 Caps Lock 键工作。如果您希望 Escape 键仍作为 Escape 键工作，您可以用 caps2esc -m 1 替换 caps2esc ，它使用 caps2esc “最小模式”并且不影响 Escape 键（有关文档，请参见 caps2esc -h ）。\n您现在只需启动 udevmon 程序，我们将使用 systemd 单元来执行此操作。\n配置 udevmon 的 systemd 服务 # 创建 systemd 服务单元文件 /etc/systemd/system/udevmon.service （如果不存在），并在其中添加内容：\n[Unit] Description=udevmon Wants=systemd-udev-settle.service After=systemd-udev-settle.service # Use `nice` to start the `udevmon` program with very high priority, # using `/etc/udevmon.yaml` as the configuration file [Service] ExecStart=/usr/bin/nice -n -20 /usr/bin/udevmon -c /etc/udevmon.yaml [Install] WantedBy=multi-user.target 此服务单元以非常高的优先级启动 udevmon 程序（ nice 允许您设置程序的调度优先级； -20 niceness 是最高可能的优先级）。确保 ExecStart 行（例如 /usr/bin/udevmon ）中的 uvdevmon 路径与 which udevmon 的输出相匹配。\n然后启用并启动 udevmon 服务：\n# Enable and start the `udevmon` service sudo systemctl enable --now udevmon.service # Optionally verify the `udevmon` service is active and running systemctl status udevmon 此时应该已经完成了，尝试使用例如 \u0026lt;CapsLock\u0026gt;-L 来清除终端屏幕（就像你通常使用 \u0026lt;Ctrl\u0026gt;-L 所做的那样）。如果启用了 udevmon 服务，则 udevmon 会自动在系统启动时启动。\n","date":"2024-04-19","externalUrl":null,"permalink":"/posts/2024/caps2esc/","section":"Posts","summary":"使用 caps2esc ，让 Caps Lock 键在单独按下时充当 Escape 键，在与其他键组合按下时充当 Control 键","title":"将 CapsLock 重映射到 Esc 和 Ctrl","type":"posts"},{"content":"","date":"2024-04-10","externalUrl":null,"permalink":"/tags/docker/","section":"Tags","summary":"","title":"Docker","type":"tags"},{"content":" https://danthesalmon.com/running-docker-on-proxmox/ 在 PVE 下的 LXC 容器内运行 Docker 容器时，若出现 unable to apply caps: operation not permitted: unknown. 则需要在 PVE 下进行一些配置\n在/etc/pve/lxc/\u0026lt;id\u0026gt;.conf中添加：\nlxc.apparmor.profile: unconfined lxc.cgroup.devices.allow: a lxc.cap.drop: ","date":"2024-04-10","externalUrl":null,"permalink":"/posts/2024/pve-lxc-docker/","section":"Posts","summary":"在PVE下的LXC容器中运行Docker容器时，若出现unable to apply caps: operation not permitted: unknown.错误，需要在PVE下进行一些配置","title":"LXC 容器中的 Docker 设置","type":"posts"},{"content":"在使用某些软件时可能会在 Log 内看到 Failed to set real-time priority for thread: Operation not permitted (1) 类似的提示，可以通过安装包 realtime-privileges 并将当前用户添加进 realtime 组中解决\n但 rtkit-daemon 会在 Log 中输出一大堆的 rtkit-daemon[1498]: Supervising 1 threads of 1 processes of 1 users. 影响其他日志的浏览\n解决方案 # 修改 rtkit-daemon.service :\n# systemctl edit rtkit-daemon [Service] LogLevelMax=5 其中 LogLevel 对应的可以有以下几个级别\n0 or emergency, (highest priority messages) 1 or alert, 2 or critical, 3 or error, 4 or warning, 5 or notice, 6 or info 7 or debuginfo (lowest priority messages) ","date":"2024-04-10","externalUrl":null,"permalink":"/posts/2024/silent-rtkit-daemon/","section":"Posts","summary":"\u0026ldquo;Failed to set real-time priority for thread: Operation not permitted\u0026rdquo;","title":"让 rtkit-daemon 闭嘴","type":"posts"},{"content":"修改 Captive Portal 解决类原生“无网络”的情况\nadb shell settings put global captive_portal_http_url http://connect.rom.miui.com/generate_204 adb shell settings put global captive_portal_https_url https://connect.rom.miui.com/generate_204 ","date":"2024-04-10","externalUrl":null,"permalink":"/posts/2024/captive-portal/","section":"Posts","summary":"修改 Captive Portal 解决类原生“无网络”的情况","title":"修改 Captive Portal","type":"posts"},{"content":"","date":"2024-02-04","externalUrl":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git","type":"tags"},{"content":" ouch stands for Obvious Unified Compression Helper.\nIt\u0026rsquo;s a CLI tool for compressing and decompressing for various formats.\nSupported formats # Format .tar .zip 7z .gz .xz, .lzma .bz, .bz2 .lz4 .sz (Snappy) .zst .rar Supported ✓ ✓¹ ✓¹ ✓² ✓ ✓ ✓ ✓² ✓ ✓³ ✓: Supports compression and decompression.\n✓¹: Due to limitations of the compression format itself, (de)compression can\u0026rsquo;t be done with streaming.\n✓²: Supported, and compression runs in parallel.\n✓³: Due to RAR\u0026rsquo;s restrictive license, only decompression and listing can be supported. If you wish to exclude non-free code from your build, you can disable RAR support by building without the unrar feature.\nBenchmarks # Compress # compress tar tar.gz tar.zst tar.xz tar.bz2 tar.lz4 tar.sz 7z zip time 0.331 3.535 1.397 5:22.61 58.079 0.430 0.304 5:27.61 29.441 size 1G 761M 754M 768M 758M 1G 1G 768M 761M cpu 99% 1170% 99% 99% 99% 99% 641% 99% 99% compress tar tar.gz tar.zst tar.xz tar.bz2 7z zip ouch 0.331 3.535 1.397 5:22.61 58.079 5:27.61 29.441 tar 0.458 29.950 1.158 5:40.00 1:02.82 p7zip 43.131 zip 29.455 Decompress # decompress tar tar.gz tar.zst tar.xz tar.bz2 tar.lz4 tar.sz 7z zip time 0.529 3.212 2.703 34.474 35.898 0.769 0.690 41.182 3.166 cpu 99% 99% 99% 99% 99% 99% 99% 99% 99% decompress tar tar.gz tar.zst tar.xz tar.bz2 tar.lz4 tar.sz 7z zip ouch 0.529 3.212 2.703 34.474 35.898 0.769 0.690 41.182 3.166 tar 0.572 4.815 1.014 33.701 35.457 0.604 0.534 p7zip 30.890 unzip 4.885 ","date":"2024-02-04","externalUrl":null,"permalink":"/posts/2024/ouch-benchmark/","section":"Posts","summary":"Simple benchmark of ouch","title":"Ouch Benchmark","type":"posts"},{"content":"批量修改 Git 仓库中的 commit author email\n安装 # 安装 git-filter-repo\n修改 # 将 E1@example.com 修改为 E2@example.com\ngit filter-repo --email-callback \u0026#39;return email if email != b\u0026#34;E1@example.com\u0026#34;else b\u0026#34;E2@example.com\u0026#34;\u0026#39; 注意 # 修改后需要强制推送才能修改远程仓库 git push -f\n","date":"2024-02-04","externalUrl":null,"permalink":"/posts/2024/git-email/","section":"Posts","summary":"如何批量修改Git仓库中的提交作者邮箱。通过使用git filter-repo命令，并需要强制推送才能修改远程仓库。","title":"批量修改 Git 历史中的用户邮箱","type":"posts"},{"content":"安装包 webp-pixbuf-loader\n","date":"2024-02-04","externalUrl":null,"permalink":"/posts/2024/nemo-webp/","section":"Posts","summary":"要在Nemo中显示WebP缩略图，需要安装webp-pixbuf-loader软件包。","title":"使 nemo 可以显示 WebP 缩略图","type":"posts"},{"content":"sudo pacman -S texlive-latexextra texlive-xetex texlive-langchinese texlive-formatsextra texlive-binextra ","date":"2024-02-04","externalUrl":null,"permalink":"/posts/2024/arch-latex/","section":"Posts","summary":"","title":"在 Arch Linux 上使用 LaTeX 需要安装的包","type":"posts"},{"content":" 本文内容来自：SSH 密钥一键配置脚本 使用教程 - P3TERX 📝 语法及选项说明 # bash \u0026lt;(curl -fsSL s.sakari.top/key.sh) [选项...] \u0026lt;参数\u0026gt;\no - 覆盖模式，必须写在最前面才会生效 g - 从 GitHub 获取公钥，参数为 GitHub 用户名 u - 从 URL 获取公钥，参数为 URL f - 从本地文件获取公钥，参数为本地文件路径 p - 修改 SSH 端口，参数为端口号 d - 禁用密码登录 🤗 使用方法 # 安装公钥 # 从 GitHub 获取公钥 # 在 GitHub 密钥管理页面 添加公钥，比如我的用户名是 sakarie9，那么在主机上输入以下命令即可：\nbash \u0026lt;(curl -fsSL s.sakari.top/key.sh) -g sakarie9 从 URL 获取公钥 # 把公钥上传到网盘，通过网盘链接获取公钥：\nbash \u0026lt;(curl -fsSL s.sakari.top/key.sh) -u https://example.com/key.pub 从本地文件获取公钥 # 通过 FTP 的方式把公钥传到 VPS 上，然后指定公钥路径：\nbash \u0026lt;(curl -fsSL s.sakari.top/key.sh) -f ~/key.pub 覆盖模式 # 使用覆盖模式（-o）将覆盖 /.ssh/authorized_keys 文件，之前的密钥会被完全替换掉，选项必须写在最前面才会生效，比如：\nbash \u0026lt;(curl -fsSL s.sakari.top/key.sh) -o -g sakarie9 或者\nbash \u0026lt;(curl -fsSL s.sakari.top/key.sh) -og sakarie9 禁用密码登录 # 在确定使用密钥能正常登录后禁用密码登录：\nbash \u0026lt;(curl -fsSL s.sakari.top/key.sh) -d 修改 SSH 端口 # 把 SSH 端口修改为 2222：\nbash \u0026lt;(curl -fsSL s.sakari.top/key.sh) -p 2222 一键操作 # 安装密钥、修改端口、禁用密码登录一键操作：\nbash \u0026lt;(curl -fsSL s.sakari.top/key.sh) -og sakarie9 -p 2222 -d 一键操作 不修改端口 # 安装密钥、禁用密码登录一键操作：\nbash \u0026lt;(curl -fsSL s.sakari.top/key.sh) -og sakarie9 -d ","date":"2023-12-23","externalUrl":null,"permalink":"/posts/2023/ssh-key-installer/","section":"Posts","summary":"","title":"SSH 密钥一键配置脚本","type":"posts"},{"content":"使用 dae 和 clash 实现全局代理，透明且高性能\nGithub 仓库\n使用项目 # dae：高性能全局透明代理 Clash.Meta：作为 dae 的上游提供代理 caddy：可选，为某些受到 SNI 阻断的服务提供直连 安装 # dae，注意 dae 对内核版本有要求\n一个正常工作的代理客户端，clash、clash-meta、clash for windows、v2ray 等均可\n配置 # clash # 本节可跳过，可使用现有的正常工作的配置文件，仅需要保证 clash 的端口和 dae node 中配置的一致。与 dae 共同使用时请保证代理的各种全局代理方案（tun、iptables 等）均已关闭\n转换订阅 # 自行搭建 proxy-provider-converter，或使用 proxy-converter.sakari.top，将 clash 订阅转换成 Proxy Provider 支持的格式，或直接使用 v2ray 订阅连接\n修改配置 # 编辑 clash/config.yaml，将转换后的链接填入 url 中\n下载 Yacd-meta，解压至配置文件中 external-ui 所在目录\n根据需要修改分流规则\ndae # 修改 dae/config.dae，将 wan_interface 的值修改为自己的网卡，可以使用 ip a 查看\n根据使用的代理在 routing 下添加规则，如 pname(clash) -\u0026gt; must_direct\ncaddy # 无直连需求可跳过，参考 在Linux上使用Caddy反代Steam社区\n","date":"2023-04-05","externalUrl":null,"permalink":"/posts/2023/dae-clash/","section":"Posts","summary":"","title":"使用 dae 和 clash 实现的全局代理方案","type":"posts"},{"content":"作为 github-actions[bot] 进行 commit，避免污染 commit 记录\n使用方式 # git config user.email \u0026#34;41898282+github-actions[bot]@users.noreply.github.com\u0026#34; git config user.name \u0026#34;github-actions[bot]\u0026#34; git commit 效果 # ","date":"2023-03-10","externalUrl":null,"permalink":"/posts/2023/github-actions-bot/","section":"Posts","summary":"","title":"作为 github-actions[bot] 进行 commit","type":"posts"},{"content":"WM 下配置系统全局光标主题\n安装 # 以 Catppuccin-Cursors 为例\n参考 Installation\nparu -S catppuccin-cursors-frappe 配置 # nwg-look # 使用 nwg-look 配置\n在鼠标光标处选择目标主题，应用\n环境变量 # export XCURSOR_THEME=catppuccin-frappe-light-cursors export XCURSOR_SIZE=32 GTK # 若已使用 nwg-look 配置,则无需修改\ngsettings set org.gnome.desktop.interface cursor-theme catppuccin-frappe-light-cursors gsettings set org.gnome.desktop.interface cursor-size 32 过时的内容 下载 # 以 Catppuccin-Frappe-Light-Cursors 为例\n从仓库下载 Catppuccin-Frappe-Light-Cursors.zip，解压至 ~/.local/share/icons\nicons ├── Catppuccin-Frappe-Light-Cursors │ ├── cursors │ └── index.theme 配置 # Qt # ~/.icons/default/index.theme\n[icon theme] Inherits=Catppuccin-Frappe-Light-Cursors 环境变量 # ~/.zlogin\nexport XCURSOR_THEME=Catppuccin-Frappe-Light-Cursors export XCURSOR_SIZE=32 GTK # gsettings set org.gnome.desktop.interface cursor-theme Catppuccin-Frappe-Light-Cursors gsettings set org.gnome.desktop.interface cursor-size 32 Hyprland # ~/.config/hypr/hyprland.conf\nexec-once = hyprctl setcursor Catppuccin-Frappe-Light-Cursors 32 ","date":"2022-12-24","externalUrl":null,"permalink":"/posts/2022/linux-cursor/","section":"Posts","summary":"WM 下配置系统全局光标主题","title":"Linux 光标主题配置","type":"posts"},{"content":"","date":"2022-07-23","externalUrl":null,"permalink":"/tags/cloudflare/","section":"Tags","summary":"","title":"Cloudflare","type":"tags"},{"content":" 2022/12/28, Heroku 将结束免费方案，此教程同步作废\nHeroku 的免费方案下，单个用户所有 app 每月的总运行时长不超过550小时，且不能绑定自己的域名，如果需要全天在线需要绑定银行卡，对于白嫖用户相当不友好。但是我们可以给 Heroku 套上一层 Cloudflare 来实现全月在线和域名绑定\n原理 # 使用 Cloudflare Workers 对 Heroku 进行反代并手动实现简单的负载均衡\n需求 # 一个使用 Cloudflare 进行域名解析的域名 两个 Heroku 账户（无需验证信用卡） 配置 # Heroku 配置 # 在两个账号下分别配置两个项目，切勿配置在同一账户下，免费时间是以账户为单位而非实例。配置过程略，根据自己需要选择，最后需要两个这样的 URL https://******.herokuapp.com/\nCloudflare 配置 # 添加 DNS 记录，类型 AAAA，名称自定，IPv6 地址为 100::，代理状态打勾，保存\nWorkers - 管理 Workers - 创建服务，服务名称自定，这里假设为 heroku-dns，创建服务\n点击快速编辑，填入以下代码，手动替换 url1 和 url2，保存并部署\naddEventListener( \u0026#34;fetch\u0026#34;,event =\u0026gt; { let url=new URL(event.request.url); let localDate = new Date(); let day = localDate.getDate(); if (day\u0026lt;15) //每月前十五天使用url1,后十五天使用url2 { url.hostname=\u0026#34;******.herokuapp.com\u0026#34;; //url1 } else { url.hostname=\u0026#34;******.herokuapp.com\u0026#34;; //url2 } //console.log(`Request url: ${url.hostname}`); let request=new Request(url,event.request); event. respondWith( fetch(request) ) } ) Workers - HTTP 路由 - 添加路由，路由 处填写 名称.域名.顶级域名/*，名称处填写第一步中 DNS 记录里填写的名称，域名填写当前在 Cloudflare 添加解析的域名，别忘了后面的 /*；服务选择第二步新建的 heroku-dns，环境 production，保存\n此时访问域名就能访问到部署在 Heroku 上的服务，可以在 Workers 的编辑界面测试，取消掉 console.log 行的注释，发送请求就能在控制台看到当前使用的是哪个 URL\n最后 # 单个账户的 550 小时用半个月是完全没有问题的，可以使用 uptime 等监控程序每15分钟一次使 Heroku 永不休眠，避免唤醒时的巨大访问延迟\n","date":"2022-07-23","externalUrl":null,"permalink":"/posts/2022/heroku-cf/","section":"Posts","summary":"","title":"Heroku+Cloudflare 免费账号实现24/7在线及域名绑定","type":"posts"},{"content":"众所周知，Java版的Minecraft是会吃掉很多内存的，但最大内存也会受到 -Xmx 等JVM参数的限制。如果它占用的内存能达到两倍的最大内存限制，甚至能吃掉所有的物理内存+虚拟内存，显然是不合理的。\n相关 Issue # radeonsi: VRAM Leak/abnormally high usage in Minecraft mod pack 问题已在新版 mesa 中有所缓解\n环境 # OS: Arch Linux x86_64 Kernel: 5.18.12-zen1-1-zen CPU: AMD Ryzen 5 5600G with Radeon Graphics (12) GPU: AMD ATI Cezanne GPU: AMD ATI Radeon RX 580 Memory: 16GB mesa 22.1.3-1 Minecraft 1.7.10 GTNewHorizons-1.7.10-2.1.2.3qf polymc 1.3.2 过程 # 初遇问题 # 给 Minecraft 分配最大 8GB 内存，加上其他程序和系统的占用，游戏打开进入服务器后内存占用会在 10GB 左右浮动，游戏过程中内存占用会不断增加，甚至用尽物理内存。此时的 java 内存占用在 10GB 左右，但 free -h 显示如下（具体数值是我编的可能对不上但大概是这个意思）\ntotal used free shared buff/cache available 内存： 15Gi 14.9Gi 0.5Gi 228Mi 0.5Gi 1.1Gi 交换： 17Gi 8Gi 9Gi 可以看出不仅物理内存用尽，虚拟内存也使用了很大一部分，但很明显已使用的内存和各进程的内存占用总和对不上。此时 Minecraft 已经开始由于内存不足进行高强度 GC 而产生间歇性卡顿，此时如果不关闭MC，待虚拟内存消耗殆尽时会因为 OOM 强行终止掉 java 进程，或者崩掉其他进程。最严重的一次似乎是崩掉了 systemd， poweroff 和 journalctl 都没有响应，其次是崩掉了 sway 窗口管理器\n但问题就来了， java 进程终止后，内存占用依旧异常，很明显我的所有进程的内存使用量总和是不可能有下图所示10.8GiB这么多的，那么多出来的内存都去哪了呢\n分析内存 # 根据 /proc/meminfo之谜 给出的公式分析内存\nMemTotal = MemFree +【Slab+ VmallocUsed + PageTables + KernelStack + HardwareCorrupted + Bounce + X】+【Active + Inactive + Unevictable + (HugePages_Total * Hugepagesize)】 发现多占用的内存数量与公式里的 X 接近，注解里表示 X表示直接通过alloc_pages/__get_free_page分配的内存，没有在/proc/meminfo中统计，不知道有多少，就像个黑洞。 猜测或许是 java 引发了内存泄漏\n更换 jdk # 此前使用的一直是 AUR 中的 jdk8-graalvm-bin，尝试更换如下几个版本的 jdk，并设置对应的 JVM 参数，但并没有明显改善\nOracle jdk8 jdk8-dragonwell jdk8-adoptopenjdk jdk8-openjdk-shenandoah jdk8-openj9 题外话，这些 jdk 之中，内存占用和性能表现最优秀的大概是 jdk8-dragonwell，有兴趣的可以试试 Alibaba Dragonwell8 JDK\n增删 mod # 由于 GTNH 这个整合包的 mod 数量有250+个，没办法一个个测试内存问题，只单独把几个优化相关的 mod 加加减减测试数次但问题依旧，直到添加了一个性能分析 mod，它告诉我现在在用核显跑 Minecraft，使用 nvtop 观察，分配的 512MB 核显显存此时将近满载，java 进程消耗了大约 200MB 的显存（至少他是这么写的）\n核显独显 # 在双显卡的 Linux 平台上，核显独显的切换可以通过使用 DRI_PRIME 实现，比如 DRI_PRIME=1 vkcube 就会调用我的独显运行\n而在 polymc 上，我设置的 env DRI_PRIME=1 并没有生效， Minecraft 依然在使用默认值也就是核显运行。重新设置 polymc，在 自定义命令-包装器命令 中填入 sh -c \u0026quot;export DRI_PRIME=1;gamemoderun $INST_JAVA \\\u0026quot;$@\\\u0026quot;\u0026quot; ，启动，通过 radeontop 和 nvtop 监控，成功在独显上运行\n显存 # 那问题是不是解决了？并没有，内存依然会溢出，但是比以前撑的时间更长了，使用 radeontop 和 nvtop 查看，发现独显的 4GB 显存已经满了，Minecraft 这个游戏能使用满 4GB 的显存明显是很不合理的，即使是这么多 mod 的大型整合包。重启再开发现，显存占用满之前内存占用都是正常的，而显存满了之后，内存占用就开始不正常了\n所以现在谜底已经很明显了，多出来的那部分 X ，就是被当成显存使用的内存。\n使用核显的时候分配的 512MB 的显存是不够用的，就会把物理内存当成显存来用，这部分就是 radeontop 中的 GTT。独显也一样，独立的显存能缓解内存爆掉的速度，但总还是会爆的\n编译 # 知道了是显存占用问题而非内存问题后，搜到了这么一个 issue\nradeonsi: VRAM Leak/abnormally high usage in Minecraft mod pack\n症状几乎和我遇到的一模一样，评论指出了可能的解决方案，通过降低 mesa 某段代码中的 buffer size 可以缓解显存占用问题，开始准备重新编译 mesa\n以下步骤基于 ArchLinux，其他发行版不能直接使用，但可以参考并手动修改编译\n使用 asp 获取 mesa 的 PKGBUILD\nmkdir ~/build cd ~/build asp update mesa asp export mesa cd mesa 修改 PKGBUILD\n在 prepare() 中添加一行 sed 命令\nprepare() { cd mesa-$pkgver sed -i \u0026#39;s/20\\*1024\\*1024/20\\*1024/g\u0026#39; src/mesa/vbo/vbo_save.h } 编译\nmakepkg -s 若提示 PGP 错误可尝试\nmakepkg -s --skippgpcheck 安装\n编译完成后目录下会有许多包，安装自己需要的包\nsudo pacman -U mesa-22.1.3-1-x86_64.pkg.tar.zst 测试 # 重启之后打开 Minecraft 测试，四个小时左右显存占用只有 1GB，虽然可能治了标没治本，但起码不用每一个小时重启电脑释放内存了\n总结 # TL;DR，解决此问题最有效的方法就是重新编译修改过的 mesa，但为什么他们会设置这么大的数值咱也不知道，至少在这个基于 Minecraft 1.7.10 的 GTNH 整合包之外的游戏里显存表现都没有什么问题，可能是旧版JDK + 旧版Minecraft + 大型整合包带来的三重 DEBUFF 吧\n","date":"2022-07-19","externalUrl":null,"permalink":"/posts/2022/minecraft-memory/","section":"Posts","summary":"","title":"Minecraft 在 Linux 下内存占用极多的问题","type":"posts"},{"content":"使用 ADB 开启 Lawnchair 应用抽屉的中英混排 无需root\n问题描述 # 在类原生系统的初次开机设置时，如果检测到国内SIM卡，系统会自动将语言切换成 中文（中国） ，而这个语言在系统的 添加语言 列表里面是没有的，你只能找到 简体中文（中国）\n类原生自带的启动器（QuickStep、Lawnchair 等）在 简体中文（中国） 下，应用抽屉会按照中文在前，英文在后（或者反过来）的方式排序，并且缺少相关的设置项；而在 中文（中国） 下，这些启动器可以正常按照中文拼音首字母进行中英混排\n简体中文（中国） | 中文（中国） 解决方案 # 手机连接电脑开启USB调试，输入\nadb shell settings put system system_locales zh-CN,zh-Hans-CN 重启，完成\n","date":"2022-07-13","externalUrl":null,"permalink":"/posts/2022/android-language/","section":"Posts","summary":"","title":"Lawnchair 应用抽屉中英混排","type":"posts"},{"content":"","date":"2022-01-20","externalUrl":null,"permalink":"/tags/windows/","section":"Tags","summary":"","title":"Windows","type":"tags"},{"content":"绕过使用原版 Windows 11 镜像安装时的硬件要求（TPM/SecureBoot）\n使用 Windows 镜像启动 # U盘写入镜像或虚拟机挂载镜像启动\n打开命令提示符 # 在 Windows 安装程序的语言选择界面，按下 Shift+F10 打开 CMD 窗口\n编辑注册表 # 在 CMD 中输入 regedit 打开注册表编辑器\n进入 HKEY_LOCAL_MACHINE\\SYSTEM\\Setup\n右键 Setup 选择 新建-项，重命名为 LabConfig\n点击 LabConfig，在右面的窗口右键新建一共三个 DWORD（32位）值，重命名如下，并将他们的数值数据改为 1\n- BypassTPMCheck - BypassRAMCheck - BypassSecureBootCheck 关闭 CMD 和 注册表编辑器 继续安装系统 # ","date":"2022-01-20","externalUrl":null,"permalink":"/posts/2022/win11-bypass/","section":"Posts","summary":"","title":"手动绕过 Windows 11 安装硬件限制","type":"posts"},{"content":"","date":"2021-11-15","externalUrl":null,"permalink":"/tags/telegram/","section":"Tags","summary":"","title":"Telegram","type":"tags"},{"content":"使用 Bot 在 Telegram 及 QQ 间转发消息，基本可以做到去 QQ 化，仅在 Telegram 上与 QQ 好友/群组互动\n简介 # 使用 Bot 在 Telegram 及 QQ 间转发消息，基本可以做到去 QQ 化，仅在 Telegram 上与 QQ 好友/群组互动\n本项目使用 Docker Compose 简化了 Telegram Bot 和 QQ Bot 的安装与配置，仅需要 Docker Compose 与流畅的国际互联网连接即可使用\n环境要求 # Docker Docker Compose 能稳定连接到Telegram服务器的网络 使用项目 # TG-EFB-QQ-Docker\nEFB-Docker\nEH Forwarder Bot Telegram Master QQ Slave QQ Plugin Mirai QQ Plugin go-cqhttp efb-filter-middleware Go-CQHttp-Docker\ngo-cqhttp 配置 # 克隆项目 # # 克隆 git clone -b go-cqhttp https://github.com/sakarie9/TG-EFB-QQ-Docker.git # 进入文件夹 cd TG-EFB-QQ-Docker 配置GOCQ端 # 编辑 gocq/config.yml 配置文件\naccount: # 账号相关 uin: 000000000 # QQ 账号 password: \u0026#39;\u0026#39; # QQ 密码，为空时使用扫码登录 （可选）修改登陆协议，运行如下命令，待提示生成 device.json 后 ctrl+c 退出，编辑 gocq/device.json，参考 设备信息\ndocker run --rm -it --name=\u0026#34;gocq\u0026#34; -v $PWD/gocq:/data xzsk2/gocqhttp-docker:latest 配置EFB端 # 获取token\n创建一个Bot，向 @BotFather 发起会话，发送指令 /newbot 开始创建Bot，创建完成后可获取token\n查看自己的Telegram ID\n向 @get_id_bot 发送/start，得到的Chat ID即为用户的Telegram ID\n打开./efb/profiles/default/blueset.telegram/config.yaml，修改下列字段，token修改为上面获取到的Bot token，admins修改为Telegram ID，注意格式\ntoken: 123456789:ABCDEFG1ABCDEFG1ABCDEFG1 admins: - 987654321 运行 # 启动 # docker-compose up -d 如需扫码登陆输入 docker logs gocq 查看二维码\n停止 # docker-compose down 自动更新 # docker run -d \\ --name watchtower \\ --restart unless-stopped \\ -v /var/run/docker.sock:/var/run/docker.sock \\ containrrr/watchtower -c \\ --interval 3600 \\ efb gocq 本地代理 # 如果你的服务器环境可以连接到Telegram服务器，可跳过本章节\n本教程使用 ssr-command-client 作为本地代理，可参考此项目文档配置\n安装\npip3 install shadowsocksr-cli 使用\n# 添加订阅链接 shadowsocksr-cli --add-url 你的ssr订阅链接 # 更新订阅 shadowsocksr-cli -u # 启动 shadowsocksr-cli --fast-node 修改EFB配置\n编辑./TG-EFB-QQ-Docker/efb/profile/default/blueset.telegram/config.yaml，添加代理\ntoken: xxx:xxx admins: - xxxxxxxx # 添加下面的两行 request_kwargs: proxy_url: socks5h://127.0.0.1:1080/ 重启\ndocker-compose down docker-compose up -d 常见问题 # 无法发送群消息，只能接收？\n无法发送大于三个字符的群消息，接收正常；好友消息的收发正常。这种情况是触发了TX的风控，一般服务器上挂12小时-2天即可正常\n","date":"2021-11-15","externalUrl":null,"permalink":"/posts/2021/tg-qq-gocq/","section":"Posts","summary":"","title":"Telegram 收发 QQ 信息 - EFB 和 GO-CQHTTP 的 Docker 部署教程","type":"posts"},{"content":"","date":"2021-05-08","externalUrl":null,"permalink":"/categories/archived/","section":"Categories","summary":"","title":"Archived","type":"categories"},{"content":" 云空调，便携小空调，为你的夏日带去清凉！\n","date":"2021-05-08","externalUrl":null,"permalink":"/posts/2021/air-conditioner-room/","section":"Posts","summary":"","title":"空调房","type":"posts"},{"content":"使用 Bot 在 Telegram 及 QQ 间转发消息，基本可以做到去 QQ 化，仅在 Telegram 上与 QQ 好友/群组互动\n简介 # 使用 Bot 在 Telegram 及 QQ 间转发消息，基本可以做到去 QQ 化，仅在 Telegram 上与 QQ 好友/群组互动\n本项目使用 Docker Compose 简化了 Telegram Bot 和 QQ Bot 的安装与配置，仅需要 Docker Compose 与流畅的国际互联网连接即可使用\n本教程为 Mirai 版本，推荐使用新版\nTelegram 收发 QQ 信息 - EFB 和 GO-CQHTTP 的 Docker 部署教程 2021-11-15\u0026middot;850 字 技术分享 Linux Docker Telegram 环境要求 # Docker Docker Compose 能稳定连接到Telegram服务器的网络 使用项目 # TG-EFB-QQ-Docker\nEFB-Docker\nEH Forwarder Bot Telegram Master QQ Slave QQ Plugin Mirai Mirai-Docker\nMirai Console Loader mirai-api-http 配置 # 克隆项目 # # 克隆 git clone -b mirai https://github.com/xzsk2/TG-EFB-QQ-Docker.git # 进入文件夹 cd TG-EFB-QQ-Docker 配置Mirai端 # 编辑./mirai/config/net.mamoe.mirai-api-http/setting.yml，修改authKey，最少8位，记下这个authKey，会在下面配置EFB的过程中用到\nauthKey: xxxxxxxx 配置EFB端 # 获取token\n创建一个Bot，向 @BotFather 发起会话，发送指令 /newbot 开始创建Bot，创建完成后可获取token\n查看自己的Telegram ID\n向 @get_id_bot 发送/start，得到的Chat ID即为用户的Telegram ID\n打开./efb/profiles/default/blueset.telegram/config.yaml，修改下列字段，token修改为上面获取到的Bot token，admins修改为Telegram ID，注意格式\ntoken: 123456789:ABCDEFG1ABCDEFG1ABCDEFG1 admins: - 987654321 打开./efb/profiles/default/milkice.qq/config.yaml，修改qq和authKey\nClient: mirai mirai: qq: xxxxxxxx # 这里换成登录的 QQ 号 host: \u0026#34;mirai\u0026#34; # 这个不要改 port: 8080 # 同上 authKey: \u0026#34;xxxxxxxx\u0026#34; # 这里填入在配置 Mirai API HTTP 时生成的 authKey 运行 # 登录QQ，在docker-compose.yml文件夹下运行\ndocker run --rm -it --name=\u0026#34;mirai\u0026#34; -p 8080:8080 -v $PWD/mirai/config:/app/config -v $PWD/mirai/bots:/app/bots xzsk2/mirai-docker:latest 使用/login登录账号\n/login \u0026lt;qq\u0026gt; \u0026lt;password\u0026gt; # 登录一个账号 出现Login successful后登录成功，再次运行\ndocker run --rm -it --name=\u0026#34;mirai\u0026#34; -p 8080:8080 -v $PWD/mirai/config:/app/config -v $PWD/mirai/bots:/app/bots xzsk2/mirai-docker:latest 使用/autologin设置自动登录\n/autoLogin add \u0026lt;account\u0026gt; \u0026lt;password\u0026gt; # 添加自动登录 之后使用CTRL+C退出容器，使用docker-compose启动\ndocker-compose up -d 本地代理 # 如果你的服务器环境可以连接到Telegram服务器，可跳过本章节\n本教程使用 ssr-command-client 作为本地代理，可参考此项目文档配置\n安装\npip3 install shadowsocksr-cli 使用\n# 添加订阅链接 shadowsocksr-cli --add-url 你的ssr订阅链接 # 更新订阅 shadowsocksr-cli -u # 启动 shadowsocksr-cli --fast-node # 修改监听地址 shadowsocksr-cli --setting-address 0.0.0.0 修改EFB配置\n编辑./TG-EFB-QQ-Docker/efb/profile/default/blueset.telegram/config.yaml，添加代理\ntoken: xxx:xxx admins: - xxxxxxxx # 添加下面的两行 request_kwargs: proxy_url: socks5h://172.17.0.1:1080/ 重启\ndocker-compose down docker-compose up -d 常见问题 # Mirai登陆失败/验证码/版本过低？\n请尝试先在本地桌面环境下部署Mirai，如需要滑动验证码请使用 mirai-login-solver-selenium，或修改登录协议\n无法发送群消息，只能接收？\n无法发送大于三个字符的群消息，接收正常；好友消息的收发正常。这种情况是触发了TX的风控，一般服务器上挂12小时-2天即可正常\n","date":"2021-05-05","externalUrl":null,"permalink":"/posts/2021/tg-qq-mirai/","section":"Posts","summary":"","title":"（旧）Telegram 收发 QQ 信息 - EFB 和 Mirai 的 Docker 部署教程","type":"posts"},{"content":" 症状 # 在使用Chrome+SwitchyOmega+Clash的环境下，SwitchyOmega的“代理”操作会将代理请求发送至Clash，由Clash判断是否使用代理。这样就造成了用户想要某个域名走代理，但是Clash规则中默认该域名直连，最终还是直连的情况。\n解决方案 # Clash配置 # 配置Clash将来自Chrome的流量全部使用代理\n进入Clash的Settings页面，选择Profiles下的Parsers，编辑配置文件预处理，参考 配置文件预处理\n其中URL修改为配置文件的URL，节点选择修改为配置文件内的proxy-groups下的name，根据情况选择\nparsers: # array - url: URL yaml: prepend-rules: - PROCESS-NAME,chrome.exe,节点选择 SwitchyOmega配置 # 设置自动切换规则，可以参考 Proxy SwitchyOmega 配置\n注意在SwitchyOmega内设置为直连的域名将不经过Clash直接访问，设置为代理的域名将无视Clash规则直接代理\n","date":"2021-04-03","externalUrl":null,"permalink":"/posts/2021/chrome-clash/","section":"Posts","summary":"","title":"Chrome+SwitchyOmega+Clash的处理","type":"posts"},{"content":" ts文件卡死是怎么回事呢？ts文件相信大家都很熟悉，但是卡死是怎么回事呢？下面就让小编带大家一起了解吧。 ts文件卡死，其实就是卡死了。那么ts文件为什么会卡死，相信大家都很好奇是怎么回事。大家可能会感到很惊讶，ts文件怎么会卡死呢？但事实就是这样，小编也感到非常惊讶。那么这就是关于ts文件卡死的事情了，大家有没有觉得很神奇呢？ 看了今天的内容，大家有什么想法呢？欢迎在评论区告诉小编一起讨论哦。\n症状 # 右键大小较大的.ts文件经常会出现资源管理器卡死或长时间未响应的情况\n解决 # 暴力方案 # 直接删除mfmpeg2srcsnk.dll\n正常方案 # 下载并打开 shexview ，找到MF MPEG Property Handler，右键Disable即可\nIcaros # 使资源管理器支持所有媒体格式的缩略图以及详细信息的软件\n下载链接\n启用前 启用后 ","date":"2021-03-22","externalUrl":null,"permalink":"/posts/2021/windows-ts/","section":"Posts","summary":"","title":"Windows10 右键 ts 文件卡死","type":"posts"},{"content":" PowerShell # 1. 在 PowerShell 窗口中运行如下指令 # if (!(Test-Path -Path $PROFILE )) { New-Item -Type File -Path $PROFILE -Force } notepad $PROFILE 2. 在打开的记事本中添加如下代码 # 注意修改第九行代理地址\n# Set-Proxy command if ($env:HTTP_PROXY -ne $null){ Write-Output \u0026#34;Proxy Enabled as $env:HTTP_PROXY\u0026#34;; } Function SetProxy() { Param( # 改成自己的代理地址 $Addr = \u0026#39;http://127.0.0.1:19810\u0026#39;, [switch]$ApplyToSystem ) $env:HTTP_PROXY = $Addr; $env:HTTPS_PROXY = $Addr; $env:http_proxy = $Addr; $env:https_proxy = $Addr; [Net.WebRequest]::DefaultWebProxy = New-Object Net.WebProxy $Addr; if ($ApplyToSystem) { $matchedResult = ValidHttpProxyFormat $Addr; # Matched result: [URL Without Protocol][Input String] if (-not ($matchedResult -eq $null)) { SetSystemProxy $matchedResult.1; } } Write-Output \u0026#34;Successful set proxy as $Addr\u0026#34;; } Function ClearProxy() { Param( $Addr = $null, [switch]$ApplyToSystem ) $env:HTTP_PROXY = $Addr; $env:HTTPS_PROXY = $Addr; $env:http_proxy = $Addr; $env:https_proxy = $Addr; [Net.WebRequest]::DefaultWebProxy = New-Object Net.WebProxy; if ($ApplyToSystem) { SetSystemProxy $null; } Write-Output \u0026#34;Successful unset all proxy variable\u0026#34;; } Function SetSystemProxy($Addr = $null) { Write-Output $Addr $proxyReg = \u0026#34;HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\u0026#34;; if ($Addr -eq $null) { Set-ItemProperty -Path $proxyReg -Name ProxyEnable -Value 0; return; } Set-ItemProperty -Path $proxyReg -Name ProxyServer -Value $Addr; Set-ItemProperty -Path $proxyReg -Name ProxyEnable -Value 1; } Function ValidHttpProxyFormat ($Addr) { $regex = \u0026#34;(?:https?:\\/\\/)(\\w+(?:.\\w+)*(?::\\d+)?)\u0026#34;; $result = $Addr -match $regex; if ($result -eq $false) { throw [System.ArgumentException]\u0026#34;The input $Addr is not a valid HTTP proxy URI.\u0026#34;; } return $Matches; } Set-Alias set-proxy SetProxy Set-Alias clear-proxy ClearProxy 3. 保存，重新打开PowerShell # 设置当前窗口代理 ：set-proxy\n设置当前窗口代理 + 系统代理：set-proxy -ApplyToSystem\n取消当前窗口代理：clear-proxy\n取消当前窗口代理 + 系统代理：clear-proxy -ApplyToSystem\nset-proxy和SetProxy，clear-proxy和ClearProxy可以互相替换\nCMD # 设置代理，窗口关闭后失效\nset http_proxy=http://127.0.0.1:19810 set https_proxy=http://127.0.0.1:19810 Git # 设置Http代理，永久生效\ngit config --global https.proxy https://127.0.0.1:19810 git config --global http.proxy http://127.0.0.1:19810 取消代理\ngit config --global --unset http.proxy git config --global --unset https.proxy ","date":"2021-03-17","externalUrl":null,"permalink":"/posts/2021/windows-proxy/","section":"Posts","summary":"","title":"Windows 下为 PowerShell/CMD/Git 设置代理","type":"posts"},{"content":"测试平台：Openwrt\n在/etc/hotplug.d/iface/下添加30-routes文件,系统将在接口状态发生生变化时执行该脚本。\n然后在30-routes中写入\n#!/bin/sh if [ \u0026#34;$ACTION\u0026#34; = \u0026#34;ifdown\u0026#34; -a \u0026#34;$INTERFACE\u0026#34; = \u0026#34;pptp-vpn0\u0026#34; ] then #在此添加断开后的代码 fi if [ \u0026#34;$ACTION\u0026#34; = \u0026#34;ifup\u0026#34; -a \u0026#34;$INTERFACE\u0026#34; = \u0026#34;pptp-vpn0\u0026#34; ] then #在此添加连接后需要执行的代码 fi 把pptp-vpn0修改为自己想要的接口名。\n比如我现在需要在pptp-vpn0断开后自动添加192.168.0.1为默认路由，则设置如下\nif [ \u0026#34;$ACTION\u0026#34; = \u0026#34;ifdown\u0026#34; -a \u0026#34;$INTERFACE\u0026#34; = \u0026#34;virtual**\u0026#34; ] then route add default gw 192.168.0.1 fi 加入了一行route add default gw 192.168.0.1\n","date":"2018-10-19","externalUrl":null,"permalink":"/posts/2018/pptp-route/","section":"Posts","summary":"","title":"如何让pptp连接/断开后自动添加路由","type":"posts"},{"content":"第十一届河南省ACM程序设计竞赛 I题\n#include \u0026#34;stdafx.h\u0026#34; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cstring\u0026gt; using namespace std; long long source[101][101];//原始矩阵 long long sourcesum; long long newm[101][101];//新矩阵 int m, n; long long a[101], b[101];//a为每行的最大数，b为每列最大数 bool av[101], bv[101];//visited long long minsum; //时间判断变量定义 long long totaltime = 0; int requiretime = 0; int T; struct zeroSave { int x; int y; }; vector\u0026lt;zeroSave\u0026gt; zs; //初始化 void init() { memset(source, -1, sizeof(source)); memset(newm, -1, sizeof(newm)); memset(a, 0, sizeof(a)); memset(b, 0, sizeof(b)); memset(av, 0, sizeof(av)); memset(bv, 0, sizeof(bv)); minsum = 0; sourcesum = 0; zs.clear(); zs.push_back({ 0 }); } //矩阵输入 void input() { cin \u0026gt;\u0026gt; totaltime \u0026gt;\u0026gt; requiretime; cin \u0026gt;\u0026gt; m \u0026gt;\u0026gt; n; for (int i = 1; i \u0026lt;= m; i++) for (int j = 1; j \u0026lt;= n; j++) { int tmp = 0; cin \u0026gt;\u0026gt; tmp; source[i][j] = tmp; sourcesum += tmp; if (!tmp) { newm[i][j] = 0; } } } //每行每列最大值计算 void maxcal() { long long max; for (int i = 1; i \u0026lt;= m; i++) { max = 0; for (int j = 1; j \u0026lt;= n; j++) { if (max \u0026lt; source[i][j]) max = source[i][j]; } a[i] = max; } for (int j = 1; j \u0026lt;= n; j++) { max = 0; for (int i = 1; i \u0026lt;= m; i++) { if (max \u0026lt; source[i][j]) max = source[i][j]; } b[j] = max; } } //矩阵构造 void construct() { //从主视图和左视图看，最优矩阵生成 for (int i = 1; i \u0026lt;= m; i++) for (int j = 1; j \u0026lt;= n; j++) if (a[i] == b[j] \u0026amp;\u0026amp; bv[j] == 0) { av[i] = 1; bv[j] = 1; if (source[i][j] != 0) { newm[i][j] = a[i]; break; } else {//碰到合并到0的情况先保存，后面处理 zeroSave temp; temp.x = i; temp.y = j; zs.push_back(temp); break; } } //剩余最大值插入 //行剩余处理 for (int i = 1; i \u0026lt;= m; i++) { if (av[i] == 1) continue; for (int j = 1; j \u0026lt;= n; j++) { if (a[i] \u0026lt;= b[j] \u0026amp;\u0026amp; source[i][j] != 0) { newm[i][j] = a[i]; av[i] = 1; break; } } } //列剩余处理 for (int j = 1; j \u0026lt;= n; j++) { if (bv[j] == 1) continue; for (int i = 1; i \u0026lt;= m; i++) { if (b[j] \u0026lt;= a[i] \u0026amp;\u0026amp; source[i][j] != 0) { newm[i][j] = b[j]; bv[j] = 1; break; } } } } //对最大值合并到0上时的处理 void zero() { for (unsigned k = 1; k \u0026lt; zs.size(); k++) { int flag = 0; //查询当前0的横方向上是否有跟最大值相等的数 for (int i = 1; i \u0026lt;= n; i++) { if (a[zs[k].x] == b[i] \u0026amp;\u0026amp; i != zs[k].y)//如果存在 { flag = 1; break; } } if (flag == 0)//如果不存在 { //横向分散 for (int i = 1; i \u0026lt;= n; i++) if (newm[zs[k].x][i] == -1) { newm[zs[k].x][i] = a[zs[k].x]; break; } //纵向分散 for (int i = 1; i \u0026lt;= m; i++) if (newm[i][zs[k].y] == -1) { newm[i][zs[k].y] = b[zs[k].y]; break; } } } } //计算新矩阵大小 void newMatrixSum() { minsum = 0; for (int i = 1; i \u0026lt;= m; i++) for (int j = 1; j \u0026lt;= n; j++) if (newm[i][j] != -1) minsum += newm[i][j]; else { minsum++; newm[i][j] = 1; } } //oj输出 void oj() { cin \u0026gt;\u0026gt; T; long long diff; while (T--) { init(); input(); maxcal(); construct(); zero(); newMatrixSum(); diff = sourcesum - minsum; if (totaltime / (double)requiretime \u0026gt; diff) { cout \u0026lt;\u0026lt; diff \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; totaltime / requiretime \u0026lt;\u0026lt; endl; } } } int main() { oj(); system(\u0026#34;pause\u0026#34;); } ","date":"2018-06-05","externalUrl":null,"permalink":"/posts/2018/zznuoj-2113/","section":"Posts","summary":"","title":"Image Recognition","type":"posts"},{"content":"雷达安装\npoj1328\n以岛屿为圆心，雷达范围为半径，计算此圆与x轴交点的线段，以此把所有岛屿的区间计算出来。\n因此，这道题就变成了在数轴上选最少的点，覆盖给定线段。\n把每条线段以右端点排序，然后进行选择即可。\nsqrt函数使用时要保证数据类型一致。\n注意输出格式以及Case的C要大写= =\n#include \u0026#34;stdafx.h\u0026#34; #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cmath\u0026gt; using namespace std; struct radarRange { double left; double right; bool operator \u0026lt; (const radarRange \u0026amp;x) const //\u0026lt;重载，用于sort函数 { if (right != x.right) return right \u0026lt; x.right; return left \u0026lt; x.left; } }; struct islandPosition { int x; int y; }; int radar() { int n, d; cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; d; if (n == 0 \u0026amp;\u0026amp; d == 0) return -2; islandPosition *p = new islandPosition[n]; radarRange *r = new radarRange[n]; for (int i = 0; i \u0026lt; n; i++) { cin \u0026gt;\u0026gt; p[i].x \u0026gt;\u0026gt; p[i].y; } if (d == 0) return -1; for (int i = 0; i \u0026lt; n; i++) if (p[i].y \u0026gt; d) { return -1; } for (int i = 0; i \u0026lt; n; i++)//计算雷达安装范围 { double tmp = sqrt(double(d *d) - double(p[i].y * p[i].y)); r[i].left = p[i].x - tmp; r[i].right = p[i].x + tmp; } //for (int i = 0; i \u0026lt; n; i++)//debug //{ //\tcout \u0026lt;\u0026lt; r[i].left \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; r[i].right \u0026lt;\u0026lt; endl; //} sort(r, r + n); //for (int i = 0; i \u0026lt; n; i++)//debug //{ //\tcout \u0026lt;\u0026lt; r[i].left \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; r[i].right \u0026lt;\u0026lt; endl; //} double start, end; int sum = 1; start = r[0].left; end = r[0].right; for (int i = 1; i \u0026lt; n; i++)//计算所需雷达数 { if (r[i].left \u0026lt;= end \u0026amp;\u0026amp; r[i].left \u0026gt;= start) { start = r[i].left; } /*if (r[i].left \u0026lt;= end \u0026amp;\u0026amp; r[i].left \u0026lt; start) { ; }*/ if (r[i].left \u0026gt; end) { start = r[i].left; end = r[i].right; sum++; } } delete[] p; delete[] r; return sum; } int main() { int tmp; int sum = 1; while (1) { tmp = radar(); if (tmp == -2) break; cout \u0026lt;\u0026lt; \u0026#34;Case \u0026#34; \u0026lt;\u0026lt; sum++ \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; tmp \u0026lt;\u0026lt; endl; } system(\u0026#34;pause\u0026#34;); } /* Sample Input 3 2 1 2 -3 1 2 1 1 2 0 2 0 0 Sample Output Case 1: 2 Case 2: 1 */ ","date":"2018-05-07","externalUrl":null,"permalink":"/posts/2018/1328/","section":"Posts","summary":"","title":"poj1328 雷达安装","type":"posts"},{"content":"最长公共子序列长度\npoj.org 1458\n状态转移方程： 最长公共子序列长度C++代码实现：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; using namespace std; int LCS(string a, string b) { int la, lb; la = a.length(); lb = b.length(); vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; c(la + 1, vector\u0026lt;int\u0026gt;(lb + 1, 0)); for (int i = 1; i \u0026lt;= la; i++) for (int j = 1; j \u0026lt;= lb; j++) { if (a[i - 1] == b[j - 1]) c[i][j] = c[i - 1][j - 1] + 1; else c[i][j] = max(c[i - 1][j], c[i][j - 1]); } return c[la][lb]; } int main() { string a, b; while (cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b) { cout \u0026lt;\u0026lt; LCS(a, b) \u0026lt;\u0026lt; endl; } return 0; } ","date":"2018-04-21","externalUrl":null,"permalink":"/posts/2018/1458/","section":"Posts","summary":"","title":"poj1458 最长公共子序列长度","type":"posts"},{"content":"Prim算法\npoj.org 2485.\n#include \u0026#34;stdafx.h\u0026#34; #include \u0026lt;iostream\u0026gt; using namespace std; #define MAX 1000 #define MAXCOST 0x3f3f3f3f int graph[MAX][MAX]; int prim(int graph[][MAX], int n) //n顶点个数 { int lowcost[MAX]; //lowcost[i]:以i为终点的边的最小权值,lowcost[i]=0表示i点加入了MST int mst[MAX]; //mst[i]:对应lowcost[i]的起点,mst[i]=0表示起点i加入MST int i, j, min, minid; int max = 0; for (i = 2; i \u0026lt;= n; i++) { lowcost[i] = graph[1][i]; //从1开始到所有点的权值 mst[i] = 1; //对应lowcost[i]的起点为1 } mst[1] = 0; //1点在MST中 for (i = 2; i \u0026lt;= n; i++) { min = MAXCOST; //min为最小权值 minid = 0; //最小权值对应的点 for (j = 2; j \u0026lt;= n; j++) { if (lowcost[j] \u0026lt; min \u0026amp;\u0026amp; lowcost[j] != 0) { min = lowcost[j]; minid = j; } } //输出示例V1-V3=1 if (min \u0026gt; max) max = min; //最小权值累加 lowcost[minid] = 0; //加入MST for (j = 2; j \u0026lt;= n; j++) //更新lowcost[]和mst[] { if (graph[minid][j] \u0026lt; lowcost[j] \u0026amp;\u0026amp; lowcost[j] != 0) { lowcost[j] = graph[minid][j]; mst[j] = minid; } } } return max; } int main() { int T; int s; int sum; memset(graph, MAXCOST, sizeof(graph)); scanf(\u0026#34;%d\u0026#34;, \u0026amp;T); while (T--) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;s); for (int i = 1; i \u0026lt; s + 1; i++) for (int j = 1; j \u0026lt; s + 1; j++) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;graph[i][j]); if (!graph[i][j]) graph[i][j] = MAXCOST; } sum = prim(graph, s); cout \u0026lt;\u0026lt; sum \u0026lt;\u0026lt; endl; } system(\u0026#34;pause\u0026#34;); } ","date":"2018-03-22","externalUrl":null,"permalink":"/posts/2018/2485/","section":"Posts","summary":"","title":"poj2485 Prim算法","type":"posts"},{"content":" About Me # About Site # ","externalUrl":null,"permalink":"/about/","section":"Sakari's Blog","summary":"","title":"About","type":"page"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]